{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=11tNJQ0z7rDK2iOmZcYxXKcfV-Wr36hpx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvtlr-otsI0o",
        "outputId": "879ac081-8377-4824-ba4f-0cef8c54d615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=11tNJQ0z7rDK2iOmZcYxXKcfV-Wr36hpx\n",
            "From (redirected): https://drive.google.com/uc?id=11tNJQ0z7rDK2iOmZcYxXKcfV-Wr36hpx&confirm=t&uuid=f4903deb-a1d1-4835-9eee-36f8ca0ebdb5\n",
            "To: /content/textgan.zip\n",
            "100% 533M/533M [00:11<00:00, 45.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/textgan.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "vrGkn95Y8c2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfMfWvoTxxEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655c4c0e-eccc-43cd-ca9b-9384844ebec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r content/TextGAN-PyTorch/requirements.txt (line 1)) (2.2.1+cu121)\n",
            "Collecting numpy==1.14.5 (from -r content/TextGAN-PyTorch/requirements.txt (line 2))\n",
            "  Downloading numpy-1.14.5.zip (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from -r content/TextGAN-PyTorch/requirements.txt (line 3)) (3.8.1)\n",
            "Collecting tqdm==4.32.1 (from -r content/TextGAN-PyTorch/requirements.txt (line 4))\n",
            "  Downloading tqdm-4.32.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.5->-r content/TextGAN-PyTorch/requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.5->-r content/TextGAN-PyTorch/requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.5->-r content/TextGAN-PyTorch/requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->-r content/TextGAN-PyTorch/requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py clean\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build numpy\n",
            "\u001b[31mERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r content/TextGAN-PyTorch/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://kheafield.com/code/kenlm.tar.gz\n",
        "!tar -xzvf kenlm.tar.gz"
      ],
      "metadata": {
        "id": "OU-J6Gu_78Se",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294e9356-93c7-4743-aca9-c92091bc7d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-06 11:41:02--  http://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://kheafield.com/code/kenlm.tar.gz [following]\n",
            "--2024-05-06 11:41:02--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: ‘kenlm.tar.gz.1’\n",
            "\n",
            "kenlm.tar.gz.1      100%[===================>] 480.36K  1.69MB/s    in 0.3s    \n",
            "\n",
            "2024-05-06 11:41:03 (1.69 MB/s) - ‘kenlm.tar.gz.1’ saved [491888/491888]\n",
            "\n",
            "kenlm/\n",
            "kenlm/include/\n",
            "kenlm/include/util/\n",
            "kenlm/include/util/string_piece.hh\n",
            "kenlm/include/util/probing_hash_table.hh\n",
            "kenlm/include/util/file_piece.hh\n",
            "kenlm/include/util/file.hh\n",
            "kenlm/include/util/read_compressed.hh\n",
            "kenlm/include/util/ersatz_progress.hh\n",
            "kenlm/include/util/pcqueue.hh\n",
            "kenlm/include/util/usage.hh\n",
            "kenlm/include/util/string_piece_hash.hh\n",
            "kenlm/include/util/sorted_uniform.hh\n",
            "kenlm/include/util/parallel_read.hh\n",
            "kenlm/include/util/thread_pool.hh\n",
            "kenlm/include/util/multi_intersection.hh\n",
            "kenlm/include/util/exception.hh\n",
            "kenlm/include/util/have.hh\n",
            "kenlm/include/util/fixed_array.hh\n",
            "kenlm/include/util/sized_iterator.hh\n",
            "kenlm/include/util/unistd.hh\n",
            "kenlm/include/util/tokenize_piece.hh\n",
            "kenlm/include/util/pool.hh\n",
            "kenlm/include/util/joint_sort.hh\n",
            "kenlm/include/util/bit_packing.hh\n",
            "kenlm/include/util/stream/\n",
            "kenlm/include/util/stream/timer.hh\n",
            "kenlm/include/util/stream/multi_stream.hh\n",
            "kenlm/include/util/stream/sort.hh\n",
            "kenlm/include/util/stream/chain.hh\n",
            "kenlm/include/util/stream/stream.hh\n",
            "kenlm/include/util/stream/io.hh\n",
            "kenlm/include/util/stream/block.hh\n",
            "kenlm/include/util/stream/line_input.hh\n",
            "kenlm/include/util/stream/config.hh\n",
            "kenlm/include/util/stream/multi_progress.hh\n",
            "kenlm/include/util/mmap.hh\n",
            "kenlm/include/util/proxy_iterator.hh\n",
            "kenlm/include/util/getopt.hh\n",
            "kenlm/include/util/murmur_hash.hh\n",
            "kenlm/include/util/scoped.hh\n",
            "kenlm/include/util/fake_ofstream.hh\n",
            "kenlm/include/lm/\n",
            "kenlm/include/lm/binary_format.hh\n",
            "kenlm/include/lm/model.hh\n",
            "kenlm/include/lm/left.hh\n",
            "kenlm/include/lm/neural/\n",
            "kenlm/include/lm/neural/wordvecs.hh\n",
            "kenlm/include/lm/read_arpa.hh\n",
            "kenlm/include/lm/bhiksha.hh\n",
            "kenlm/include/lm/partial.hh\n",
            "kenlm/include/lm/virtual_interface.hh\n",
            "kenlm/include/lm/interpolate/\n",
            "kenlm/include/lm/interpolate/arpa_to_stream.hh\n",
            "kenlm/include/lm/model_type.hh\n",
            "kenlm/include/lm/builder/\n",
            "kenlm/include/lm/builder/joint_order.hh\n",
            "kenlm/include/lm/builder/adjust_counts.hh\n",
            "kenlm/include/lm/builder/header_info.hh\n",
            "kenlm/include/lm/builder/output.hh\n",
            "kenlm/include/lm/builder/print.hh\n",
            "kenlm/include/lm/builder/ngram_stream.hh\n",
            "kenlm/include/lm/builder/hash_gamma.hh\n",
            "kenlm/include/lm/builder/sort.hh\n",
            "kenlm/include/lm/builder/discount.hh\n",
            "kenlm/include/lm/builder/ngram.hh\n",
            "kenlm/include/lm/builder/pipeline.hh\n",
            "kenlm/include/lm/builder/corpus_count.hh\n",
            "kenlm/include/lm/builder/interpolate.hh\n",
            "kenlm/include/lm/builder/initial_probabilities.hh\n",
            "kenlm/include/lm/max_order.hh\n",
            "kenlm/include/lm/blank.hh\n",
            "kenlm/include/lm/enumerate_vocab.hh\n",
            "kenlm/include/lm/quantize.hh\n",
            "kenlm/include/lm/weights.hh\n",
            "kenlm/include/lm/trie_sort.hh\n",
            "kenlm/include/lm/search_hashed.hh\n",
            "kenlm/include/lm/facade.hh\n",
            "kenlm/include/lm/value.hh\n",
            "kenlm/include/lm/return.hh\n",
            "kenlm/include/lm/vocab.hh\n",
            "kenlm/include/lm/sizes.hh\n",
            "kenlm/include/lm/ngram_query.hh\n",
            "kenlm/include/lm/lm_exception.hh\n",
            "kenlm/include/lm/filter/\n",
            "kenlm/include/lm/filter/wrapper.hh\n",
            "kenlm/include/lm/filter/count_io.hh\n",
            "kenlm/include/lm/filter/arpa_io.hh\n",
            "kenlm/include/lm/filter/vocab.hh\n",
            "kenlm/include/lm/filter/format.hh\n",
            "kenlm/include/lm/filter/thread.hh\n",
            "kenlm/include/lm/filter/phrase.hh\n",
            "kenlm/include/lm/wrappers/\n",
            "kenlm/include/lm/wrappers/nplm.hh\n",
            "kenlm/include/lm/word_index.hh\n",
            "kenlm/include/lm/state.hh\n",
            "kenlm/include/lm/config.hh\n",
            "kenlm/include/lm/trie.hh\n",
            "kenlm/include/lm/search_trie.hh\n",
            "kenlm/include/lm/value_build.hh\n",
            "kenlm/COPYING.3\n",
            "kenlm/util/\n",
            "kenlm/util/string_piece.hh\n",
            "kenlm/util/probing_hash_table.hh\n",
            "kenlm/util/bit_packing.cc\n",
            "kenlm/util/integer_to_string.cc\n",
            "kenlm/util/cat_compressed_main.cc\n",
            "kenlm/util/spaces.cc\n",
            "kenlm/util/file_piece.hh\n",
            "kenlm/util/bit_packing_test.cc\n",
            "kenlm/util/file.hh\n",
            "kenlm/util/string_stream_test.cc\n",
            "kenlm/util/read_compressed.hh\n",
            "kenlm/util/file_piece.cc\n",
            "kenlm/util/ersatz_progress.hh\n",
            "kenlm/util/pcqueue.hh\n",
            "kenlm/util/double-conversion/\n",
            "kenlm/util/double-conversion/fixed-dtoa.cc\n",
            "kenlm/util/double-conversion/cached-powers.h\n",
            "kenlm/util/double-conversion/fixed-dtoa.h\n",
            "kenlm/util/double-conversion/bignum.cc\n",
            "kenlm/util/double-conversion/bignum-dtoa.cc\n",
            "kenlm/util/double-conversion/bignum.h\n",
            "kenlm/util/double-conversion/utils.h\n",
            "kenlm/util/double-conversion/strtod.cc\n",
            "kenlm/util/double-conversion/ieee.h\n",
            "kenlm/util/double-conversion/cached-powers.cc\n",
            "kenlm/util/double-conversion/fast-dtoa.cc\n",
            "kenlm/util/double-conversion/strtod.h\n",
            "kenlm/util/double-conversion/diy-fp.h\n",
            "kenlm/util/double-conversion/diy-fp.cc\n",
            "kenlm/util/double-conversion/bignum-dtoa.h\n",
            "kenlm/util/double-conversion/CMakeLists.txt\n",
            "kenlm/util/double-conversion/fast-dtoa.h\n",
            "kenlm/util/double-conversion/LICENSE\n",
            "kenlm/util/double-conversion/double-conversion.h\n",
            "kenlm/util/double-conversion/double-conversion.cc\n",
            "kenlm/util/usage.hh\n",
            "kenlm/util/string_piece.cc\n",
            "kenlm/util/read_compressed.cc\n",
            "kenlm/util/mmap.cc\n",
            "kenlm/util/string_piece_hash.hh\n",
            "kenlm/util/sorted_uniform.hh\n",
            "kenlm/util/float_to_string.hh\n",
            "kenlm/util/ersatz_progress.cc\n",
            "kenlm/util/parallel_read.hh\n",
            "kenlm/util/exception.cc\n",
            "kenlm/util/thread_pool.hh\n",
            "kenlm/util/fake_ostream.hh\n",
            "kenlm/util/multi_intersection.hh\n",
            "kenlm/util/multi_intersection_test.cc\n",
            "kenlm/util/exception.hh\n",
            "kenlm/util/have.hh\n",
            "kenlm/util/float_to_string.cc\n",
            "kenlm/util/fixed_array.hh\n",
            "kenlm/util/pool.cc\n",
            "kenlm/util/murmur_hash.cc\n",
            "kenlm/util/integer_to_string.hh\n",
            "kenlm/util/sized_iterator.hh\n",
            "kenlm/util/parallel_read.cc\n",
            "kenlm/util/tokenize_piece.hh\n",
            "kenlm/util/pool.hh\n",
            "kenlm/util/joint_sort.hh\n",
            "kenlm/util/read_compressed_test.cc\n",
            "kenlm/util/usage.cc\n",
            "kenlm/util/bit_packing.hh\n",
            "kenlm/util/probing_hash_table_benchmark_main.cc\n",
            "kenlm/util/scoped.cc\n",
            "kenlm/util/file_piece_test.cc\n",
            "kenlm/util/probing_hash_table_test.cc\n",
            "kenlm/util/stream/\n",
            "kenlm/util/stream/multi_progress.cc\n",
            "kenlm/util/stream/rewindable_stream.cc\n",
            "kenlm/util/stream/typed_stream.hh\n",
            "kenlm/util/stream/stream_test.cc\n",
            "kenlm/util/stream/chain.cc\n",
            "kenlm/util/stream/line_input.cc\n",
            "kenlm/util/stream/multi_stream.hh\n",
            "kenlm/util/stream/sort.hh\n",
            "kenlm/util/stream/chain.hh\n",
            "kenlm/util/stream/rewindable_stream_test.cc\n",
            "kenlm/util/stream/stream.hh\n",
            "kenlm/util/stream/io.hh\n",
            "kenlm/util/stream/count_records.cc\n",
            "kenlm/util/stream/sort_test.cc\n",
            "kenlm/util/stream/io.cc\n",
            "kenlm/util/stream/block.hh\n",
            "kenlm/util/stream/rewindable_stream.hh\n",
            "kenlm/util/stream/io_test.cc\n",
            "kenlm/util/stream/line_input.hh\n",
            "kenlm/util/stream/count_records.hh\n",
            "kenlm/util/stream/CMakeLists.txt\n",
            "kenlm/util/stream/config.hh\n",
            "kenlm/util/stream/multi_progress.hh\n",
            "kenlm/util/sorted_uniform_test.cc\n",
            "kenlm/util/spaces.hh\n",
            "kenlm/util/mmap.hh\n",
            "kenlm/util/proxy_iterator.hh\n",
            "kenlm/util/getopt.hh\n",
            "kenlm/util/joint_sort_test.cc\n",
            "kenlm/util/CMakeLists.txt\n",
            "kenlm/util/tokenize_piece_test.cc\n",
            "kenlm/util/getopt.c\n",
            "kenlm/util/integer_to_string_test.cc\n",
            "kenlm/util/string_stream.hh\n",
            "kenlm/util/file.cc\n",
            "kenlm/util/murmur_hash.hh\n",
            "kenlm/util/pcqueue_test.cc\n",
            "kenlm/util/file_stream.hh\n",
            "kenlm/util/sized_iterator_test.cc\n",
            "kenlm/util/scoped.hh\n",
            "kenlm/BUILDING\n",
            "kenlm/COPYING\n",
            "kenlm/compile_query_only.sh\n",
            "kenlm/.github/\n",
            "kenlm/.github/workflows/\n",
            "kenlm/.github/workflows/ubuntu.yml\n",
            "kenlm/.github/workflows/mac.yml\n",
            "kenlm/.github/workflows/windows.yml\n",
            "kenlm/.gitignore\n",
            "kenlm/python/\n",
            "kenlm/python/kenlm.pyx\n",
            "kenlm/python/score_sentence.cc\n",
            "kenlm/python/kenlm.cpp\n",
            "kenlm/python/example.py\n",
            "kenlm/python/score_sentence.hh\n",
            "kenlm/python/_kenlm.pxd\n",
            "kenlm/python/CMakeLists.txt\n",
            "kenlm/README.md\n",
            "kenlm/clean_query_only.sh\n",
            "kenlm/setup.py\n",
            "kenlm/cmake/\n",
            "kenlm/cmake/modules/\n",
            "kenlm/cmake/modules/FindEigen3.cmake\n",
            "kenlm/cmake/kenlmConfig.cmake.in\n",
            "kenlm/cmake/KenLMFunctions.cmake\n",
            "kenlm/GIT_REVISION\n",
            "kenlm/COPYING.LESSER.3\n",
            "kenlm/lm/\n",
            "kenlm/lm/binary_format.hh\n",
            "kenlm/lm/binary_format.cc\n",
            "kenlm/lm/model.hh\n",
            "kenlm/lm/left.hh\n",
            "kenlm/lm/read_arpa.hh\n",
            "kenlm/lm/bhiksha.hh\n",
            "kenlm/lm/partial.hh\n",
            "kenlm/lm/virtual_interface.hh\n",
            "kenlm/lm/test.arpa\n",
            "kenlm/lm/interpolate/\n",
            "kenlm/lm/interpolate/tune_instances.hh\n",
            "kenlm/lm/interpolate/interpolate_info.hh\n",
            "kenlm/lm/interpolate/bounded_sequence_encoding.cc\n",
            "kenlm/lm/interpolate/tune_instances_test.cc\n",
            "kenlm/lm/interpolate/backoff_reunification.hh\n",
            "kenlm/lm/interpolate/tune_derivatives.hh\n",
            "kenlm/lm/interpolate/normalize_test.cc\n",
            "kenlm/lm/interpolate/normalize.cc\n",
            "kenlm/lm/interpolate/backoff_matrix.hh\n",
            "kenlm/lm/interpolate/streaming_example_main.cc\n",
            "kenlm/lm/interpolate/backoff_reunification.cc\n",
            "kenlm/lm/interpolate/tune_matrix.hh\n",
            "kenlm/lm/interpolate/universal_vocab.hh\n",
            "kenlm/lm/interpolate/pipeline.cc\n",
            "kenlm/lm/interpolate/tune_instances.cc\n",
            "kenlm/lm/interpolate/pipeline.hh\n",
            "kenlm/lm/interpolate/merge_vocab.cc\n",
            "kenlm/lm/interpolate/interpolate_main.cc\n",
            "kenlm/lm/interpolate/merge_vocab.hh\n",
            "kenlm/lm/interpolate/normalize.hh\n",
            "kenlm/lm/interpolate/tune_weights.cc\n",
            "kenlm/lm/interpolate/backoff_reunification_test.cc\n",
            "kenlm/lm/interpolate/tune_derivatives.cc\n",
            "kenlm/lm/interpolate/bounded_sequence_encoding_test.cc\n",
            "kenlm/lm/interpolate/universal_vocab.cc\n",
            "kenlm/lm/interpolate/split_worker.hh\n",
            "kenlm/lm/interpolate/merge_vocab_test.cc\n",
            "kenlm/lm/interpolate/CMakeLists.txt\n",
            "kenlm/lm/interpolate/tune_weights.hh\n",
            "kenlm/lm/interpolate/merge_probabilities.hh\n",
            "kenlm/lm/interpolate/tune_derivatives_test.cc\n",
            "kenlm/lm/interpolate/bounded_sequence_encoding.hh\n",
            "kenlm/lm/interpolate/merge_probabilities.cc\n",
            "kenlm/lm/interpolate/split_worker.cc\n",
            "kenlm/lm/partial_test.cc\n",
            "kenlm/lm/test_nounk.arpa\n",
            "kenlm/lm/model_type.hh\n",
            "kenlm/lm/builder/\n",
            "kenlm/lm/builder/adjust_counts.hh\n",
            "kenlm/lm/builder/lmplz_main.cc\n",
            "kenlm/lm/builder/header_info.hh\n",
            "kenlm/lm/builder/count_ngrams_main.cc\n",
            "kenlm/lm/builder/output.hh\n",
            "kenlm/lm/builder/combine_counts.hh\n",
            "kenlm/lm/builder/pipeline.cc\n",
            "kenlm/lm/builder/hash_gamma.hh\n",
            "kenlm/lm/builder/discount.hh\n",
            "kenlm/lm/builder/README.md\n",
            "kenlm/lm/builder/pipeline.hh\n",
            "kenlm/lm/builder/payload.hh\n",
            "kenlm/lm/builder/output.cc\n",
            "kenlm/lm/builder/dump_counts_main.cc\n",
            "kenlm/lm/builder/corpus_count.hh\n",
            "kenlm/lm/builder/initial_probabilities.cc\n",
            "kenlm/lm/builder/interpolate.hh\n",
            "kenlm/lm/builder/debug_print.hh\n",
            "kenlm/lm/builder/adjust_counts_test.cc\n",
            "kenlm/lm/builder/TODO\n",
            "kenlm/lm/builder/adjust_counts.cc\n",
            "kenlm/lm/builder/CMakeLists.txt\n",
            "kenlm/lm/builder/corpus_count_test.cc\n",
            "kenlm/lm/builder/initial_probabilities.hh\n",
            "kenlm/lm/builder/interpolate.cc\n",
            "kenlm/lm/builder/corpus_count.cc\n",
            "kenlm/lm/config.cc\n",
            "kenlm/lm/max_order.hh\n",
            "kenlm/lm/blank.hh\n",
            "kenlm/lm/trie.cc\n",
            "kenlm/lm/enumerate_vocab.hh\n",
            "kenlm/lm/quantize.cc\n",
            "kenlm/lm/model_test.cc\n",
            "kenlm/lm/sizes.cc\n",
            "kenlm/lm/virtual_interface.cc\n",
            "kenlm/lm/quantize.hh\n",
            "kenlm/lm/weights.hh\n",
            "kenlm/lm/trie_sort.hh\n",
            "kenlm/lm/fragment_main.cc\n",
            "kenlm/lm/kenlm_benchmark_main.cc\n",
            "kenlm/lm/search_hashed.hh\n",
            "kenlm/lm/facade.hh\n",
            "kenlm/lm/common/\n",
            "kenlm/lm/common/joint_order.hh\n",
            "kenlm/lm/common/model_buffer.cc\n",
            "kenlm/lm/common/compare.hh\n",
            "kenlm/lm/common/renumber.cc\n",
            "kenlm/lm/common/print.cc\n",
            "kenlm/lm/common/size_option.hh\n",
            "kenlm/lm/common/model_buffer_test.cc\n",
            "kenlm/lm/common/print.hh\n",
            "kenlm/lm/common/ngram_stream.hh\n",
            "kenlm/lm/common/test_data/\n",
            "kenlm/lm/common/test_data/toy1.arpa\n",
            "kenlm/lm/common/test_data/bigendian/\n",
            "kenlm/lm/common/test_data/bigendian/toy1.2\n",
            "kenlm/lm/common/test_data/bigendian/toy1.1\n",
            "kenlm/lm/common/test_data/bigendian/toy1.3\n",
            "kenlm/lm/common/test_data/bigendian/toy0.1\n",
            "kenlm/lm/common/test_data/bigendian/toy1.vocab\n",
            "kenlm/lm/common/test_data/bigendian/toy0.vocab\n",
            "kenlm/lm/common/test_data/bigendian/toy0.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/bigendian/toy1.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/bigendian/toy0.2\n",
            "kenlm/lm/common/test_data/bigendian/toy0.3\n",
            "kenlm/lm/common/test_data/generate.sh\n",
            "kenlm/lm/common/test_data/littleendian/\n",
            "kenlm/lm/common/test_data/littleendian/toy1.2\n",
            "kenlm/lm/common/test_data/littleendian/toy1.1\n",
            "kenlm/lm/common/test_data/littleendian/toy1.3\n",
            "kenlm/lm/common/test_data/littleendian/toy0.1\n",
            "kenlm/lm/common/test_data/littleendian/toy1.vocab\n",
            "kenlm/lm/common/test_data/littleendian/toy0.vocab\n",
            "kenlm/lm/common/test_data/littleendian/toy0.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/littleendian/toy1.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/littleendian/toy0.2\n",
            "kenlm/lm/common/test_data/littleendian/toy0.3\n",
            "kenlm/lm/common/test_data/toy0.arpa\n",
            "kenlm/lm/common/ngram.hh\n",
            "kenlm/lm/common/size_option.cc\n",
            "kenlm/lm/common/model_buffer.hh\n",
            "kenlm/lm/common/CMakeLists.txt\n",
            "kenlm/lm/common/special.hh\n",
            "kenlm/lm/common/renumber.hh\n",
            "kenlm/lm/value.hh\n",
            "kenlm/lm/lm_exception.cc\n",
            "kenlm/lm/left_test.cc\n",
            "kenlm/lm/return.hh\n",
            "kenlm/lm/vocab.hh\n",
            "kenlm/lm/build_binary_main.cc\n",
            "kenlm/lm/bhiksha.cc\n",
            "kenlm/lm/value_build.cc\n",
            "kenlm/lm/model.cc\n",
            "kenlm/lm/sizes.hh\n",
            "kenlm/lm/ngram_query.hh\n",
            "kenlm/lm/lm_exception.hh\n",
            "kenlm/lm/vocab.cc\n",
            "kenlm/lm/filter/\n",
            "kenlm/lm/filter/phrase_table_vocab_main.cc\n",
            "kenlm/lm/filter/wrapper.hh\n",
            "kenlm/lm/filter/filter_main.cc\n",
            "kenlm/lm/filter/count_io.hh\n",
            "kenlm/lm/filter/phrase.cc\n",
            "kenlm/lm/filter/arpa_io.hh\n",
            "kenlm/lm/filter/vocab.hh\n",
            "kenlm/lm/filter/format.hh\n",
            "kenlm/lm/filter/thread.hh\n",
            "kenlm/lm/filter/vocab.cc\n",
            "kenlm/lm/filter/arpa_io.cc\n",
            "kenlm/lm/filter/CMakeLists.txt\n",
            "kenlm/lm/filter/phrase.hh\n",
            "kenlm/lm/wrappers/\n",
            "kenlm/lm/wrappers/README\n",
            "kenlm/lm/wrappers/nplm.hh\n",
            "kenlm/lm/wrappers/nplm.cc\n",
            "kenlm/lm/search_trie.cc\n",
            "kenlm/lm/trie_sort.cc\n",
            "kenlm/lm/word_index.hh\n",
            "kenlm/lm/state.hh\n",
            "kenlm/lm/CMakeLists.txt\n",
            "kenlm/lm/query_main.cc\n",
            "kenlm/lm/read_arpa.cc\n",
            "kenlm/lm/config.hh\n",
            "kenlm/lm/trie.hh\n",
            "kenlm/lm/search_trie.hh\n",
            "kenlm/lm/search_hashed.cc\n",
            "kenlm/lm/value_build.hh\n",
            "kenlm/CMakeLists.txt\n",
            "kenlm/LICENSE\n",
            "kenlm/Doxyfile\n",
            "kenlm/MANIFEST.in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd kenlm && mkdir -p build && cd build && cmake .. && make -j 4 && pip install https://github.com/kpu/kenlm/archive/master.zip"
      ],
      "metadata": {
        "id": "IXxTXU3H8dTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b7c874-baaa-4afd-831d-354dce4ab7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version \"1.74.0\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework \n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done (1.2s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "[ 40%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 56%] Built target kenlm_filter\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 61%] Built target probing_hash_table_benchmark\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 77%] Built target fragment\n",
            "[ 78%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 82%] Built target query\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 85%] Built target phrase_table_vocab\n",
            "[ 86%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 92%] Built target kenlm_benchmark\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 93%] Built target filter\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 95%] Built target kenlm_builder\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.6/553.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184348 sha256=ea36eb259b7baf43718275ffd46471f5013a5e2168963b05a8bf0b437c5fcb3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uypmzuug/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aogvUjmsHgEp",
        "outputId": "7cba5da6-be76-45cf-f313-80524e471916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd content/TextGAN-PyTorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1SvJfiJmC0",
        "outputId": "2fb9bc65-c3cf-415a-d823-1273c3b95288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/TextGAN-PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение генератора на Трансформере"
      ],
      "metadata": {
        "id": "n9fsH5NTdw-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --run_model catgan --dataset L1 --if_real_data 1 --k_label 5 --loss_type ragan --gen_lr 0.0001 --gen_adv_lr 0.00001 --mle_epoch 300 --adv_epoch 10 --d_step 10 --d_epoch 5"
      ],
      "metadata": {
        "id": "GFa1K3OqdedC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b5f63d-86fb-491f-8787-f2aec8005987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "> training arguments:\n",
            ">>> if_test: False\n",
            ">>> run_model: catgan\n",
            ">>> k_label: 5\n",
            ">>> dataset: L1\n",
            ">>> model_type: vanilla\n",
            ">>> loss_type: ragan\n",
            ">>> mu_type: ragan\n",
            ">>> eval_type: Ra\n",
            ">>> d_type: Ra\n",
            ">>> if_real_data: 1\n",
            ">>> cuda: True\n",
            ">>> device: 0\n",
            ">>> devices: 0\n",
            ">>> shuffle: False\n",
            ">>> gen_init: truncated_normal\n",
            ">>> dis_init: uniform\n",
            ">>> n_parent: 1\n",
            ">>> eval_b_num: 8\n",
            ">>> lambda_fq: 1.0\n",
            ">>> lambda_fd: 0.0\n",
            ">>> d_out_mean: True\n",
            ">>> freeze_dis: False\n",
            ">>> freeze_clas: False\n",
            ">>> use_all_real_fake: False\n",
            ">>> use_population: False\n",
            ">>> samples_num: 10000\n",
            ">>> vocab_size: 3104\n",
            ">>> mle_epoch: 300\n",
            ">>> clas_pre_epoch: 10\n",
            ">>> adv_epoch: 10\n",
            ">>> inter_epoch: 15\n",
            ">>> batch_size: 64\n",
            ">>> max_seq_len: 31\n",
            ">>> start_letter: 1\n",
            ">>> padding_idx: 0\n",
            ">>> gen_lr: 0.0001\n",
            ">>> gen_adv_lr: 1e-05\n",
            ">>> dis_lr: 0.0001\n",
            ">>> clip_norm: 5.0\n",
            ">>> pre_log_step: 10\n",
            ">>> adv_log_step: 20\n",
            ">>> train_data: dataset/L1.txt\n",
            ">>> test_data: dataset/testdata/L1_test.txt\n",
            ">>> temp_adpt: exp\n",
            ">>> evo_temp_step: 1\n",
            ">>> temperature: 1\n",
            ">>> ora_pretrain: True\n",
            ">>> gen_pretrain: False\n",
            ">>> dis_pretrain: False\n",
            ">>> adv_g_step: 1\n",
            ">>> rollout_num: 16\n",
            ">>> gen_embed_dim: 32\n",
            ">>> gen_hidden_dim: 32\n",
            ">>> goal_size: 16\n",
            ">>> step_size: 4\n",
            ">>> mem_slots: 1\n",
            ">>> num_heads: 2\n",
            ">>> head_size: 256\n",
            ">>> d_step: 10\n",
            ">>> d_epoch: 5\n",
            ">>> adv_d_step: 5\n",
            ">>> adv_d_epoch: 3\n",
            ">>> dis_embed_dim: 64\n",
            ">>> dis_hidden_dim: 64\n",
            ">>> num_rep: 64\n",
            ">>> use_nll_oracle: True\n",
            ">>> use_nll_gen: True\n",
            ">>> use_nll_div: True\n",
            ">>> use_bleu: True\n",
            ">>> use_self_bleu: False\n",
            ">>> use_clas_acc: True\n",
            ">>> use_ppl: False\n",
            ">>> log_file: log/log_0506_1145_08.txt\n",
            ">>> save_root: save/20240506/L1/catgan_vanilla_dt-Ra_lt-ragan_mt-ra_et-Ra_sl31_temp1_lfd0.0_T0506_1145_08/\n",
            ">>> signal_file: run_signal.txt\n",
            ">>> tips: \n",
            "====================================================================================================\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "Start training Classifier...\n",
            "[PRE-CLAS] epoch 0: c_loss = 1.5965, c_acc = 0.3203, eval_acc = 0.3816, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 1: c_loss = 1.5588, c_acc = 0.3750, eval_acc = 0.3816, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 2: c_loss = 1.4871, c_acc = 0.3750, eval_acc = 0.3816, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 3: c_loss = 1.4378, c_acc = 0.3750, eval_acc = 0.3816, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 4: c_loss = 1.4276, c_acc = 0.3750, eval_acc = 0.3810, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 5: c_loss = 1.3946, c_acc = 0.3750, eval_acc = 0.3816, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 6: c_loss = 1.3762, c_acc = 0.3802, eval_acc = 0.3816, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 7: c_loss = 1.3448, c_acc = 0.3750, eval_acc = 0.3816, max_eval_acc = 0.3816\n",
            "[PRE-CLAS] epoch 8: c_loss = 1.3054, c_acc = 0.3750, eval_acc = 0.3834, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 9: c_loss = 1.2659, c_acc = 0.3724, eval_acc = 0.3870, max_eval_acc = 0.3870\n",
            "Starting Generator-0 MLE Training...\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[MLE-GEN] epoch 0 : pre_loss = 5.3036, BLEU-[2, 3, 4, 5] = [[0.072, 0.034, 0.024, 0.021], [0.093, 0.041, 0.028, 0.024], [0.044, 0.025, 0.02, 0.018], [0.084, 0.038, 0.026, 0.021], [0.053, 0.029, 0.022, 0.02]], NLL_gen = [4.3748, 4.4027, 4.1135, 4.6275, 3.8922], NLL_div = [4.6997, 4.6969, 4.1122, 5.0165, 4.1249], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.997, 0.0, 0.0054, 0.0]\n",
            "[MLE-GEN] epoch 10 : pre_loss = 3.5785, BLEU-[2, 3, 4, 5] = [[0.163, 0.055, 0.034, 0.026], [0.203, 0.065, 0.038, 0.028], [0.089, 0.043, 0.031, 0.027], [0.194, 0.061, 0.034, 0.025], [0.101, 0.045, 0.032, 0.027]], NLL_gen = [3.5304, 3.6132, 3.3347, 3.7174, 3.0884], NLL_div = [3.8636, 3.94, 3.1168, 4.1286, 3.5045], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9907, 0.0, 0.0257, 0.0]\n",
            "[MLE-GEN] epoch 20 : pre_loss = 3.3792, BLEU-[2, 3, 4, 5] = [[0.183, 0.062, 0.036, 0.027], [0.198, 0.062, 0.035, 0.025], [0.1, 0.045, 0.031, 0.026], [0.222, 0.065, 0.036, 0.025], [0.115, 0.048, 0.033, 0.027]], NLL_gen = [3.3218, 3.4515, 3.0358, 3.5557, 2.8004], NLL_div = [3.4516, 3.5477, 2.5522, 3.6658, 2.7163], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9917, 0.0, 0.0237, 0.0]\n",
            "[MLE-GEN] epoch 30 : pre_loss = 3.2712, BLEU-[2, 3, 4, 5] = [[0.186, 0.061, 0.036, 0.026], [0.214, 0.07, 0.039, 0.028], [0.108, 0.046, 0.031, 0.026], [0.238, 0.072, 0.037, 0.026], [0.135, 0.056, 0.037, 0.03]], NLL_gen = [3.2086, 3.3537, 2.8915, 3.4683, 2.6662], NLL_div = [3.2338, 3.4299, 2.6006, 3.5737, 2.4041], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9892, 0.0, 0.0255, 0.0]\n",
            "[MLE-GEN] epoch 40 : pre_loss = 3.1811, BLEU-[2, 3, 4, 5] = [[0.213, 0.066, 0.037, 0.027], [0.233, 0.072, 0.039, 0.028], [0.102, 0.039, 0.026, 0.021], [0.265, 0.079, 0.04, 0.027], [0.129, 0.05, 0.033, 0.027]], NLL_gen = [3.121, 3.2701, 2.7679, 3.4092, 2.5477], NLL_div = [3.2764, 3.3465, 3.0286, 3.4862, 2.7602], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9895, 0.0, 0.0322, 0.0]\n",
            "[MLE-GEN] epoch 50 : pre_loss = 3.0719, BLEU-[2, 3, 4, 5] = [[0.194, 0.062, 0.036, 0.026], [0.226, 0.071, 0.039, 0.028], [0.112, 0.044, 0.029, 0.024], [0.26, 0.076, 0.04, 0.028], [0.157, 0.059, 0.038, 0.03]], NLL_gen = [3.0103, 3.1651, 2.6699, 3.3141, 2.4341], NLL_div = [3.1536, 3.2131, 2.7795, 3.3292, 2.4862], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9897, 0.0, 0.025, 0.0]\n",
            "[MLE-GEN] epoch 60 : pre_loss = 2.9650, BLEU-[2, 3, 4, 5] = [[0.21, 0.067, 0.039, 0.029], [0.249, 0.077, 0.042, 0.03], [0.121, 0.045, 0.029, 0.023], [0.28, 0.081, 0.042, 0.029], [0.15, 0.057, 0.036, 0.029]], NLL_gen = [2.9044, 3.0627, 2.5615, 3.2234, 2.3135], NLL_div = [3.0206, 3.0912, 2.7546, 3.2281, 2.4946], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9914, 0.0, 0.0259, 0.0]\n",
            "[MLE-GEN] epoch 70 : pre_loss = 2.8709, BLEU-[2, 3, 4, 5] = [[0.239, 0.076, 0.042, 0.03], [0.282, 0.087, 0.045, 0.031], [0.12, 0.045, 0.029, 0.023], [0.302, 0.087, 0.043, 0.029], [0.155, 0.056, 0.035, 0.027]], NLL_gen = [2.8113, 2.9626, 2.4835, 3.1108, 2.2333], NLL_div = [2.8952, 3.1171, 2.8956, 3.2177, 2.5483], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9897, 0.0, 0.029, 0.0]\n",
            "[MLE-GEN] epoch 80 : pre_loss = 2.7364, BLEU-[2, 3, 4, 5] = [[0.251, 0.078, 0.042, 0.029], [0.285, 0.093, 0.049, 0.033], [0.135, 0.05, 0.031, 0.024], [0.328, 0.095, 0.046, 0.031], [0.166, 0.06, 0.037, 0.029]], NLL_gen = [2.6777, 2.8371, 2.3741, 2.998, 2.1109], NLL_div = [2.8882, 3.0037, 2.7267, 3.0985, 2.4299], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9922, 0.0, 0.0233, 0.0]\n",
            "[MLE-GEN] epoch 90 : pre_loss = 2.6188, BLEU-[2, 3, 4, 5] = [[0.26, 0.082, 0.043, 0.03], [0.321, 0.113, 0.058, 0.037], [0.128, 0.048, 0.03, 0.023], [0.319, 0.102, 0.049, 0.032], [0.197, 0.07, 0.042, 0.032]], NLL_gen = [2.5486, 2.7161, 2.2671, 2.8871, 2.0], NLL_div = [2.8438, 2.8945, 2.5458, 3.0442, 2.2977], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9913, 0.0, 0.0244, 0.0]\n",
            "[MLE-GEN] epoch 100 : pre_loss = 2.4808, BLEU-[2, 3, 4, 5] = [[0.288, 0.093, 0.047, 0.031], [0.331, 0.115, 0.059, 0.037], [0.133, 0.049, 0.031, 0.025], [0.345, 0.101, 0.049, 0.032], [0.213, 0.074, 0.043, 0.032]], NLL_gen = [2.4319, 2.5931, 2.1694, 2.7562, 1.897], NLL_div = [2.7706, 2.8881, 2.532, 2.9967, 2.2898], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9903, 0.0, 0.0302, 0.0]\n",
            "[MLE-GEN] epoch 110 : pre_loss = 2.3682, BLEU-[2, 3, 4, 5] = [[0.252, 0.085, 0.044, 0.031], [0.295, 0.11, 0.056, 0.036], [0.137, 0.049, 0.031, 0.024], [0.358, 0.112, 0.053, 0.034], [0.197, 0.069, 0.041, 0.031]], NLL_gen = [2.3529, 2.5223, 2.1122, 2.6773, 1.8344], NLL_div = [2.8035, 2.9454, 2.5366, 2.9782, 2.2727], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9916, 0.0, 0.0274, 0.0]\n",
            "[MLE-GEN] epoch 120 : pre_loss = 2.2542, BLEU-[2, 3, 4, 5] = [[0.24, 0.081, 0.042, 0.029], [0.29, 0.11, 0.055, 0.035], [0.111, 0.042, 0.028, 0.022], [0.335, 0.113, 0.055, 0.034], [0.183, 0.064, 0.037, 0.028]], NLL_gen = [2.2077, 2.3731, 2.0529, 2.5486, 1.7375], NLL_div = [2.8127, 2.9639, 2.5172, 3.11, 2.3969], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9908, 0.0, 0.0303, 0.0]\n",
            "[MLE-GEN] epoch 130 : pre_loss = 2.0906, BLEU-[2, 3, 4, 5] = [[0.252, 0.083, 0.046, 0.032], [0.308, 0.112, 0.06, 0.039], [0.143, 0.055, 0.034, 0.027], [0.345, 0.114, 0.057, 0.036], [0.181, 0.067, 0.041, 0.032]], NLL_gen = [2.0176, 2.1728, 1.8541, 2.3614, 1.5765], NLL_div = [2.5192, 2.6292, 2.1712, 2.8514, 2.0626], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9871, 0.0, 0.0295, 0.0]\n",
            "[MLE-GEN] epoch 140 : pre_loss = 1.9479, BLEU-[2, 3, 4, 5] = [[0.285, 0.097, 0.051, 0.035], [0.344, 0.141, 0.075, 0.046], [0.151, 0.056, 0.034, 0.026], [0.369, 0.127, 0.06, 0.038], [0.197, 0.075, 0.044, 0.033]], NLL_gen = [1.8946, 2.0527, 1.7768, 2.2453, 1.4831], NLL_div = [2.377, 2.4827, 2.1074, 2.6786, 1.9681], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9905, 0.0, 0.0254, 0.0]\n",
            "[MLE-GEN] epoch 150 : pre_loss = 1.8701, BLEU-[2, 3, 4, 5] = [[0.312, 0.104, 0.055, 0.037], [0.355, 0.147, 0.077, 0.047], [0.152, 0.054, 0.033, 0.025], [0.38, 0.136, 0.064, 0.039], [0.222, 0.084, 0.049, 0.036]], NLL_gen = [1.7896, 1.9457, 1.6722, 2.1304, 1.4038], NLL_div = [2.3431, 2.4071, 2.0719, 2.5898, 1.893], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9902, 0.0, 0.0264, 0.0]\n",
            "[MLE-GEN] epoch 160 : pre_loss = 1.7123, BLEU-[2, 3, 4, 5] = [[0.296, 0.101, 0.053, 0.036], [0.346, 0.145, 0.076, 0.049], [0.149, 0.055, 0.034, 0.027], [0.388, 0.137, 0.067, 0.042], [0.212, 0.081, 0.048, 0.035]], NLL_gen = [1.664, 1.8028, 1.5998, 1.9714, 1.3153], NLL_div = [2.2104, 2.3416, 1.9496, 2.4527, 1.833], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9894, 0.0, 0.0338, 0.0]\n",
            "[MLE-GEN] epoch 170 : pre_loss = 1.6291, BLEU-[2, 3, 4, 5] = [[0.347, 0.118, 0.056, 0.036], [0.393, 0.16, 0.086, 0.054], [0.167, 0.061, 0.037, 0.028], [0.436, 0.159, 0.072, 0.043], [0.252, 0.091, 0.051, 0.036]], NLL_gen = [1.5746, 1.7097, 1.5146, 1.8976, 1.2501], NLL_div = [2.2344, 2.2981, 1.9486, 2.4236, 1.8332], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9893, 0.0, 0.0361, 0.0]\n",
            "[MLE-GEN] epoch 180 : pre_loss = 1.5027, BLEU-[2, 3, 4, 5] = [[0.335, 0.113, 0.058, 0.038], [0.387, 0.164, 0.084, 0.051], [0.166, 0.058, 0.036, 0.027], [0.411, 0.15, 0.071, 0.042], [0.245, 0.093, 0.052, 0.038]], NLL_gen = [1.4416, 1.5798, 1.4206, 1.7391, 1.1498], NLL_div = [2.1037, 2.1983, 1.8939, 2.325, 1.7536], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9924, 0.0, 0.0284, 0.0]\n",
            "[MLE-GEN] epoch 190 : pre_loss = 1.4097, BLEU-[2, 3, 4, 5] = [[0.332, 0.113, 0.059, 0.038], [0.396, 0.18, 0.096, 0.057], [0.16, 0.058, 0.036, 0.028], [0.433, 0.171, 0.08, 0.047], [0.233, 0.087, 0.05, 0.036]], NLL_gen = [1.3586, 1.4874, 1.3524, 1.6438, 1.0858], NLL_div = [2.0831, 2.1616, 1.8711, 2.2642, 1.7526], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9923, 0.0, 0.0311, 0.0]\n",
            "[MLE-GEN] epoch 200 : pre_loss = 1.3271, BLEU-[2, 3, 4, 5] = [[0.334, 0.123, 0.065, 0.042], [0.421, 0.189, 0.094, 0.056], [0.162, 0.061, 0.037, 0.028], [0.415, 0.162, 0.083, 0.05], [0.234, 0.086, 0.048, 0.035]], NLL_gen = [1.2783, 1.4065, 1.2971, 1.566, 1.0301], NLL_div = [1.9844, 2.0765, 1.7912, 2.1429, 1.6548], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9921, 0.0, 0.0251, 0.0]\n",
            "[MLE-GEN] epoch 210 : pre_loss = 1.2513, BLEU-[2, 3, 4, 5] = [[0.325, 0.111, 0.058, 0.038], [0.424, 0.19, 0.1, 0.058], [0.167, 0.063, 0.038, 0.028], [0.433, 0.164, 0.079, 0.047], [0.232, 0.083, 0.047, 0.034]], NLL_gen = [1.2166, 1.3397, 1.2502, 1.5003, 0.9795], NLL_div = [1.9568, 2.0411, 1.7437, 2.2056, 1.6541], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9934, 0.0, 0.0301, 0.0]\n",
            "[MLE-GEN] epoch 220 : pre_loss = 1.2070, BLEU-[2, 3, 4, 5] = [[0.352, 0.131, 0.067, 0.043], [0.419, 0.198, 0.103, 0.063], [0.182, 0.065, 0.038, 0.028], [0.456, 0.193, 0.092, 0.055], [0.238, 0.09, 0.05, 0.036]], NLL_gen = [1.1773, 1.3016, 1.238, 1.4333, 0.9698], NLL_div = [1.9204, 1.9941, 1.7651, 2.0882, 1.6061], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9927, 0.0, 0.0283, 0.0]\n",
            "[MLE-GEN] epoch 230 : pre_loss = 1.1205, BLEU-[2, 3, 4, 5] = [[0.345, 0.126, 0.064, 0.04], [0.394, 0.181, 0.096, 0.058], [0.179, 0.065, 0.039, 0.029], [0.449, 0.193, 0.094, 0.055], [0.26, 0.1, 0.056, 0.04]], NLL_gen = [1.0789, 1.1932, 1.1458, 1.3214, 0.8819], NLL_div = [1.8678, 1.9392, 1.6509, 2.0115, 1.5303], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9942, 0.0, 0.0277, 0.0]\n",
            "[MLE-GEN] epoch 240 : pre_loss = 1.0387, BLEU-[2, 3, 4, 5] = [[0.354, 0.125, 0.062, 0.04], [0.409, 0.186, 0.097, 0.057], [0.171, 0.064, 0.039, 0.03], [0.423, 0.176, 0.083, 0.05], [0.241, 0.09, 0.051, 0.036]], NLL_gen = [1.0162, 1.1306, 1.0936, 1.2542, 0.8367], NLL_div = [1.8427, 1.9524, 1.6446, 2.0273, 1.5509], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9895, 0.0, 0.0272, 0.0]\n",
            "[MLE-GEN] epoch 250 : pre_loss = 1.0072, BLEU-[2, 3, 4, 5] = [[0.351, 0.122, 0.059, 0.038], [0.437, 0.208, 0.11, 0.064], [0.187, 0.066, 0.038, 0.029], [0.472, 0.211, 0.106, 0.061], [0.257, 0.095, 0.053, 0.037]], NLL_gen = [1.0027, 1.1093, 1.1013, 1.2312, 0.8147], NLL_div = [1.7933, 1.847, 1.5862, 1.9359, 1.4956], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9936, 0.0, 0.0298, 0.0]\n",
            "[MLE-GEN] epoch 260 : pre_loss = 0.9494, BLEU-[2, 3, 4, 5] = [[0.357, 0.13, 0.065, 0.041], [0.418, 0.194, 0.101, 0.058], [0.18, 0.065, 0.038, 0.028], [0.464, 0.204, 0.095, 0.054], [0.262, 0.1, 0.057, 0.04]], NLL_gen = [0.9402, 1.0387, 1.0363, 1.1415, 0.766], NLL_div = [1.7915, 1.8736, 1.6201, 1.9424, 1.4994], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9919, 0.0, 0.0309, 0.0]\n",
            "[MLE-GEN] epoch 270 : pre_loss = 0.8718, BLEU-[2, 3, 4, 5] = [[0.361, 0.136, 0.067, 0.044], [0.448, 0.223, 0.118, 0.07], [0.172, 0.062, 0.037, 0.028], [0.477, 0.213, 0.11, 0.067], [0.254, 0.095, 0.056, 0.041]], NLL_gen = [0.8672, 0.9581, 0.9696, 1.0623, 0.7144], NLL_div = [1.6865, 1.7639, 1.5302, 1.8115, 1.4086], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9924, 0.0, 0.0328, 0.0]\n",
            "[MLE-GEN] epoch 280 : pre_loss = 0.8423, BLEU-[2, 3, 4, 5] = [[0.379, 0.155, 0.081, 0.051], [0.421, 0.188, 0.096, 0.058], [0.179, 0.064, 0.037, 0.028], [0.454, 0.188, 0.093, 0.056], [0.254, 0.093, 0.052, 0.037]], NLL_gen = [0.849, 0.9384, 0.9838, 1.0602, 0.7039], NLL_div = [1.6745, 1.7534, 1.5225, 1.8236, 1.4053], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.992, 0.0, 0.033, 0.0]\n",
            "[MLE-GEN] epoch 290 : pre_loss = 0.7917, BLEU-[2, 3, 4, 5] = [[0.378, 0.157, 0.081, 0.051], [0.435, 0.201, 0.107, 0.065], [0.206, 0.076, 0.042, 0.031], [0.479, 0.211, 0.103, 0.059], [0.252, 0.101, 0.06, 0.042]], NLL_gen = [0.7866, 0.8776, 0.9164, 0.9664, 0.6523], NLL_div = [1.592, 1.7021, 1.46, 1.7654, 1.3541], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9912, 0.0, 0.0378, 0.0]\n",
            "[MLE-GEN] epoch 299 : pre_loss = 0.7479, BLEU-[2, 3, 4, 5] = [[0.386, 0.152, 0.074, 0.048], [0.42, 0.189, 0.096, 0.058], [0.176, 0.066, 0.04, 0.03], [0.492, 0.223, 0.113, 0.066], [0.261, 0.099, 0.059, 0.042]], NLL_gen = [0.7495, 0.8359, 0.8898, 0.9274, 0.6263], NLL_div = [1.5438, 1.6186, 1.3988, 1.6591, 1.2903], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9894, 0.0, 0.0398, 0.0]\n",
            "Save pre-trained generator: pretrain/L1/gen_MLE_pretrain_catgan_vanilla_sl31_sn10000.pt0\n",
            "  0% 0/10 [00:03<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/content/TextGAN-PyTorch/main.py\", line 169, in <module>\n",
            "    inst._run()\n",
            "  File \"/content/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 111, in _run\n",
            "    score, fit_score, select_mu = self.evolve_generator(cfg.ADV_g_step)\n",
            "  File \"/content/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 180, in evolve_generator\n",
            "    self.variation(evo_g_step, criterionG)\n",
            "  File \"/content/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 323, in variation\n",
            "    dis_real_samples, dis_gen_samples = self.prepare_train_data('G')\n",
            "  File \"/content/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 427, in prepare_train_data\n",
            "    gen_samples_list = [\n",
            "  File \"/content/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 428, in <listcomp>\n",
            "    self.gen.sample(cfg.batch_size, cfg.batch_size, one_hot=True, label_i=i)\n",
            "  File \"/content/content/TextGAN-PyTorch/models/CatGAN_G.py\", line 133, in sample\n",
            "    all_preds = torch.zeros(batch_size, self.max_seq_len, self.vocab_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1688, in __getattr__\n",
            "    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
            "AttributeError: 'CatGAN_G' object has no attribute 'vocab_size'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/content.zip /content/content"
      ],
      "metadata": {
        "id": "yVxlSoVbeAQZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}