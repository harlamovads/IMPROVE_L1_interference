{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vPLuGsjLqS6"
      },
      "source": [
        "### GAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1qzJSH5oEReG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMq_PKfGyT3M",
        "outputId": "530d9d01-9cc7-4db8-ab32-52e7fd207536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "for root, dir, files in os.walk('/content/TextGAN-PyTorch/dataset/testdata'):\n",
        "    print(files)\n",
        "    for filik in files:\n",
        "        if filik.endswith('.txt'):\n",
        "            with open('/content/TextGAN-PyTorch/dataset/testdata/' + filik, 'r') as f:\n",
        "              with open(filik[:-4] + '_short.txt', 'w+') as wf:\n",
        "                for line in f.readlines():\n",
        "                    if len(line) < 40:\n",
        "                        wf.write(line)\n",
        "                    if len(line) > 60:\n",
        "                        wf.write(line[0:41])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub_Q3_NHM7sy",
        "outputId": "45451b4f-b559-4128-9879-e589f593443b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TextGAN-PyTorch'...\n",
            "remote: Enumerating objects: 2200, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 2200 (delta 1), reused 4 (delta 0), pack-reused 2193\u001b[K\n",
            "Receiving objects: 100% (2200/2200), 19.39 MiB | 7.73 MiB/s, done.\n",
            "Resolving deltas: 100% (1531/1531), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/williamSYSU/TextGAN-PyTorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLeRo_ColxS5",
        "outputId": "e24b4f19-fcdf-44ec-db29-cbed4ece9b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r TextGAN-PyTorch/requirements.txt (line 1)) (2.2.1+cu121)\n",
            "Collecting numpy==1.14.5 (from -r TextGAN-PyTorch/requirements.txt (line 2))\n",
            "  Downloading numpy-1.14.5.zip (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from -r TextGAN-PyTorch/requirements.txt (line 3)) (3.8.1)\n",
            "Collecting tqdm==4.32.1 (from -r TextGAN-PyTorch/requirements.txt (line 4))\n",
            "  Downloading tqdm-4.32.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.5->-r TextGAN-PyTorch/requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.5->-r TextGAN-PyTorch/requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.5->-r TextGAN-PyTorch/requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->-r TextGAN-PyTorch/requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py clean\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build numpy\n",
            "\u001b[31mERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r TextGAN-PyTorch/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B2gASAvmL_A",
        "outputId": "8b5ee504-867c-47b5-c8e3-3ebaaad520e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-06 22:53:19--  http://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://kheafield.com/code/kenlm.tar.gz [following]\n",
            "--2024-05-06 22:53:19--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: ‘kenlm.tar.gz’\n",
            "\n",
            "kenlm.tar.gz        100%[===================>] 480.36K  1.68MB/s    in 0.3s    \n",
            "\n",
            "2024-05-06 22:53:20 (1.68 MB/s) - ‘kenlm.tar.gz’ saved [491888/491888]\n",
            "\n",
            "kenlm/\n",
            "kenlm/include/\n",
            "kenlm/include/util/\n",
            "kenlm/include/util/string_piece.hh\n",
            "kenlm/include/util/probing_hash_table.hh\n",
            "kenlm/include/util/file_piece.hh\n",
            "kenlm/include/util/file.hh\n",
            "kenlm/include/util/read_compressed.hh\n",
            "kenlm/include/util/ersatz_progress.hh\n",
            "kenlm/include/util/pcqueue.hh\n",
            "kenlm/include/util/usage.hh\n",
            "kenlm/include/util/string_piece_hash.hh\n",
            "kenlm/include/util/sorted_uniform.hh\n",
            "kenlm/include/util/parallel_read.hh\n",
            "kenlm/include/util/thread_pool.hh\n",
            "kenlm/include/util/multi_intersection.hh\n",
            "kenlm/include/util/exception.hh\n",
            "kenlm/include/util/have.hh\n",
            "kenlm/include/util/fixed_array.hh\n",
            "kenlm/include/util/sized_iterator.hh\n",
            "kenlm/include/util/unistd.hh\n",
            "kenlm/include/util/tokenize_piece.hh\n",
            "kenlm/include/util/pool.hh\n",
            "kenlm/include/util/joint_sort.hh\n",
            "kenlm/include/util/bit_packing.hh\n",
            "kenlm/include/util/stream/\n",
            "kenlm/include/util/stream/timer.hh\n",
            "kenlm/include/util/stream/multi_stream.hh\n",
            "kenlm/include/util/stream/sort.hh\n",
            "kenlm/include/util/stream/chain.hh\n",
            "kenlm/include/util/stream/stream.hh\n",
            "kenlm/include/util/stream/io.hh\n",
            "kenlm/include/util/stream/block.hh\n",
            "kenlm/include/util/stream/line_input.hh\n",
            "kenlm/include/util/stream/config.hh\n",
            "kenlm/include/util/stream/multi_progress.hh\n",
            "kenlm/include/util/mmap.hh\n",
            "kenlm/include/util/proxy_iterator.hh\n",
            "kenlm/include/util/getopt.hh\n",
            "kenlm/include/util/murmur_hash.hh\n",
            "kenlm/include/util/scoped.hh\n",
            "kenlm/include/util/fake_ofstream.hh\n",
            "kenlm/include/lm/\n",
            "kenlm/include/lm/binary_format.hh\n",
            "kenlm/include/lm/model.hh\n",
            "kenlm/include/lm/left.hh\n",
            "kenlm/include/lm/neural/\n",
            "kenlm/include/lm/neural/wordvecs.hh\n",
            "kenlm/include/lm/read_arpa.hh\n",
            "kenlm/include/lm/bhiksha.hh\n",
            "kenlm/include/lm/partial.hh\n",
            "kenlm/include/lm/virtual_interface.hh\n",
            "kenlm/include/lm/interpolate/\n",
            "kenlm/include/lm/interpolate/arpa_to_stream.hh\n",
            "kenlm/include/lm/model_type.hh\n",
            "kenlm/include/lm/builder/\n",
            "kenlm/include/lm/builder/joint_order.hh\n",
            "kenlm/include/lm/builder/adjust_counts.hh\n",
            "kenlm/include/lm/builder/header_info.hh\n",
            "kenlm/include/lm/builder/output.hh\n",
            "kenlm/include/lm/builder/print.hh\n",
            "kenlm/include/lm/builder/ngram_stream.hh\n",
            "kenlm/include/lm/builder/hash_gamma.hh\n",
            "kenlm/include/lm/builder/sort.hh\n",
            "kenlm/include/lm/builder/discount.hh\n",
            "kenlm/include/lm/builder/ngram.hh\n",
            "kenlm/include/lm/builder/pipeline.hh\n",
            "kenlm/include/lm/builder/corpus_count.hh\n",
            "kenlm/include/lm/builder/interpolate.hh\n",
            "kenlm/include/lm/builder/initial_probabilities.hh\n",
            "kenlm/include/lm/max_order.hh\n",
            "kenlm/include/lm/blank.hh\n",
            "kenlm/include/lm/enumerate_vocab.hh\n",
            "kenlm/include/lm/quantize.hh\n",
            "kenlm/include/lm/weights.hh\n",
            "kenlm/include/lm/trie_sort.hh\n",
            "kenlm/include/lm/search_hashed.hh\n",
            "kenlm/include/lm/facade.hh\n",
            "kenlm/include/lm/value.hh\n",
            "kenlm/include/lm/return.hh\n",
            "kenlm/include/lm/vocab.hh\n",
            "kenlm/include/lm/sizes.hh\n",
            "kenlm/include/lm/ngram_query.hh\n",
            "kenlm/include/lm/lm_exception.hh\n",
            "kenlm/include/lm/filter/\n",
            "kenlm/include/lm/filter/wrapper.hh\n",
            "kenlm/include/lm/filter/count_io.hh\n",
            "kenlm/include/lm/filter/arpa_io.hh\n",
            "kenlm/include/lm/filter/vocab.hh\n",
            "kenlm/include/lm/filter/format.hh\n",
            "kenlm/include/lm/filter/thread.hh\n",
            "kenlm/include/lm/filter/phrase.hh\n",
            "kenlm/include/lm/wrappers/\n",
            "kenlm/include/lm/wrappers/nplm.hh\n",
            "kenlm/include/lm/word_index.hh\n",
            "kenlm/include/lm/state.hh\n",
            "kenlm/include/lm/config.hh\n",
            "kenlm/include/lm/trie.hh\n",
            "kenlm/include/lm/search_trie.hh\n",
            "kenlm/include/lm/value_build.hh\n",
            "kenlm/COPYING.3\n",
            "kenlm/util/\n",
            "kenlm/util/string_piece.hh\n",
            "kenlm/util/probing_hash_table.hh\n",
            "kenlm/util/bit_packing.cc\n",
            "kenlm/util/integer_to_string.cc\n",
            "kenlm/util/cat_compressed_main.cc\n",
            "kenlm/util/spaces.cc\n",
            "kenlm/util/file_piece.hh\n",
            "kenlm/util/bit_packing_test.cc\n",
            "kenlm/util/file.hh\n",
            "kenlm/util/string_stream_test.cc\n",
            "kenlm/util/read_compressed.hh\n",
            "kenlm/util/file_piece.cc\n",
            "kenlm/util/ersatz_progress.hh\n",
            "kenlm/util/pcqueue.hh\n",
            "kenlm/util/double-conversion/\n",
            "kenlm/util/double-conversion/fixed-dtoa.cc\n",
            "kenlm/util/double-conversion/cached-powers.h\n",
            "kenlm/util/double-conversion/fixed-dtoa.h\n",
            "kenlm/util/double-conversion/bignum.cc\n",
            "kenlm/util/double-conversion/bignum-dtoa.cc\n",
            "kenlm/util/double-conversion/bignum.h\n",
            "kenlm/util/double-conversion/utils.h\n",
            "kenlm/util/double-conversion/strtod.cc\n",
            "kenlm/util/double-conversion/ieee.h\n",
            "kenlm/util/double-conversion/cached-powers.cc\n",
            "kenlm/util/double-conversion/fast-dtoa.cc\n",
            "kenlm/util/double-conversion/strtod.h\n",
            "kenlm/util/double-conversion/diy-fp.h\n",
            "kenlm/util/double-conversion/diy-fp.cc\n",
            "kenlm/util/double-conversion/bignum-dtoa.h\n",
            "kenlm/util/double-conversion/CMakeLists.txt\n",
            "kenlm/util/double-conversion/fast-dtoa.h\n",
            "kenlm/util/double-conversion/LICENSE\n",
            "kenlm/util/double-conversion/double-conversion.h\n",
            "kenlm/util/double-conversion/double-conversion.cc\n",
            "kenlm/util/usage.hh\n",
            "kenlm/util/string_piece.cc\n",
            "kenlm/util/read_compressed.cc\n",
            "kenlm/util/mmap.cc\n",
            "kenlm/util/string_piece_hash.hh\n",
            "kenlm/util/sorted_uniform.hh\n",
            "kenlm/util/float_to_string.hh\n",
            "kenlm/util/ersatz_progress.cc\n",
            "kenlm/util/parallel_read.hh\n",
            "kenlm/util/exception.cc\n",
            "kenlm/util/thread_pool.hh\n",
            "kenlm/util/fake_ostream.hh\n",
            "kenlm/util/multi_intersection.hh\n",
            "kenlm/util/multi_intersection_test.cc\n",
            "kenlm/util/exception.hh\n",
            "kenlm/util/have.hh\n",
            "kenlm/util/float_to_string.cc\n",
            "kenlm/util/fixed_array.hh\n",
            "kenlm/util/pool.cc\n",
            "kenlm/util/murmur_hash.cc\n",
            "kenlm/util/integer_to_string.hh\n",
            "kenlm/util/sized_iterator.hh\n",
            "kenlm/util/parallel_read.cc\n",
            "kenlm/util/tokenize_piece.hh\n",
            "kenlm/util/pool.hh\n",
            "kenlm/util/joint_sort.hh\n",
            "kenlm/util/read_compressed_test.cc\n",
            "kenlm/util/usage.cc\n",
            "kenlm/util/bit_packing.hh\n",
            "kenlm/util/probing_hash_table_benchmark_main.cc\n",
            "kenlm/util/scoped.cc\n",
            "kenlm/util/file_piece_test.cc\n",
            "kenlm/util/probing_hash_table_test.cc\n",
            "kenlm/util/stream/\n",
            "kenlm/util/stream/multi_progress.cc\n",
            "kenlm/util/stream/rewindable_stream.cc\n",
            "kenlm/util/stream/typed_stream.hh\n",
            "kenlm/util/stream/stream_test.cc\n",
            "kenlm/util/stream/chain.cc\n",
            "kenlm/util/stream/line_input.cc\n",
            "kenlm/util/stream/multi_stream.hh\n",
            "kenlm/util/stream/sort.hh\n",
            "kenlm/util/stream/chain.hh\n",
            "kenlm/util/stream/rewindable_stream_test.cc\n",
            "kenlm/util/stream/stream.hh\n",
            "kenlm/util/stream/io.hh\n",
            "kenlm/util/stream/count_records.cc\n",
            "kenlm/util/stream/sort_test.cc\n",
            "kenlm/util/stream/io.cc\n",
            "kenlm/util/stream/block.hh\n",
            "kenlm/util/stream/rewindable_stream.hh\n",
            "kenlm/util/stream/io_test.cc\n",
            "kenlm/util/stream/line_input.hh\n",
            "kenlm/util/stream/count_records.hh\n",
            "kenlm/util/stream/CMakeLists.txt\n",
            "kenlm/util/stream/config.hh\n",
            "kenlm/util/stream/multi_progress.hh\n",
            "kenlm/util/sorted_uniform_test.cc\n",
            "kenlm/util/spaces.hh\n",
            "kenlm/util/mmap.hh\n",
            "kenlm/util/proxy_iterator.hh\n",
            "kenlm/util/getopt.hh\n",
            "kenlm/util/joint_sort_test.cc\n",
            "kenlm/util/CMakeLists.txt\n",
            "kenlm/util/tokenize_piece_test.cc\n",
            "kenlm/util/getopt.c\n",
            "kenlm/util/integer_to_string_test.cc\n",
            "kenlm/util/string_stream.hh\n",
            "kenlm/util/file.cc\n",
            "kenlm/util/murmur_hash.hh\n",
            "kenlm/util/pcqueue_test.cc\n",
            "kenlm/util/file_stream.hh\n",
            "kenlm/util/sized_iterator_test.cc\n",
            "kenlm/util/scoped.hh\n",
            "kenlm/BUILDING\n",
            "kenlm/COPYING\n",
            "kenlm/compile_query_only.sh\n",
            "kenlm/.github/\n",
            "kenlm/.github/workflows/\n",
            "kenlm/.github/workflows/ubuntu.yml\n",
            "kenlm/.github/workflows/mac.yml\n",
            "kenlm/.github/workflows/windows.yml\n",
            "kenlm/.gitignore\n",
            "kenlm/python/\n",
            "kenlm/python/kenlm.pyx\n",
            "kenlm/python/score_sentence.cc\n",
            "kenlm/python/kenlm.cpp\n",
            "kenlm/python/example.py\n",
            "kenlm/python/score_sentence.hh\n",
            "kenlm/python/_kenlm.pxd\n",
            "kenlm/python/CMakeLists.txt\n",
            "kenlm/README.md\n",
            "kenlm/clean_query_only.sh\n",
            "kenlm/setup.py\n",
            "kenlm/cmake/\n",
            "kenlm/cmake/modules/\n",
            "kenlm/cmake/modules/FindEigen3.cmake\n",
            "kenlm/cmake/kenlmConfig.cmake.in\n",
            "kenlm/cmake/KenLMFunctions.cmake\n",
            "kenlm/GIT_REVISION\n",
            "kenlm/COPYING.LESSER.3\n",
            "kenlm/lm/\n",
            "kenlm/lm/binary_format.hh\n",
            "kenlm/lm/binary_format.cc\n",
            "kenlm/lm/model.hh\n",
            "kenlm/lm/left.hh\n",
            "kenlm/lm/read_arpa.hh\n",
            "kenlm/lm/bhiksha.hh\n",
            "kenlm/lm/partial.hh\n",
            "kenlm/lm/virtual_interface.hh\n",
            "kenlm/lm/test.arpa\n",
            "kenlm/lm/interpolate/\n",
            "kenlm/lm/interpolate/tune_instances.hh\n",
            "kenlm/lm/interpolate/interpolate_info.hh\n",
            "kenlm/lm/interpolate/bounded_sequence_encoding.cc\n",
            "kenlm/lm/interpolate/tune_instances_test.cc\n",
            "kenlm/lm/interpolate/backoff_reunification.hh\n",
            "kenlm/lm/interpolate/tune_derivatives.hh\n",
            "kenlm/lm/interpolate/normalize_test.cc\n",
            "kenlm/lm/interpolate/normalize.cc\n",
            "kenlm/lm/interpolate/backoff_matrix.hh\n",
            "kenlm/lm/interpolate/streaming_example_main.cc\n",
            "kenlm/lm/interpolate/backoff_reunification.cc\n",
            "kenlm/lm/interpolate/tune_matrix.hh\n",
            "kenlm/lm/interpolate/universal_vocab.hh\n",
            "kenlm/lm/interpolate/pipeline.cc\n",
            "kenlm/lm/interpolate/tune_instances.cc\n",
            "kenlm/lm/interpolate/pipeline.hh\n",
            "kenlm/lm/interpolate/merge_vocab.cc\n",
            "kenlm/lm/interpolate/interpolate_main.cc\n",
            "kenlm/lm/interpolate/merge_vocab.hh\n",
            "kenlm/lm/interpolate/normalize.hh\n",
            "kenlm/lm/interpolate/tune_weights.cc\n",
            "kenlm/lm/interpolate/backoff_reunification_test.cc\n",
            "kenlm/lm/interpolate/tune_derivatives.cc\n",
            "kenlm/lm/interpolate/bounded_sequence_encoding_test.cc\n",
            "kenlm/lm/interpolate/universal_vocab.cc\n",
            "kenlm/lm/interpolate/split_worker.hh\n",
            "kenlm/lm/interpolate/merge_vocab_test.cc\n",
            "kenlm/lm/interpolate/CMakeLists.txt\n",
            "kenlm/lm/interpolate/tune_weights.hh\n",
            "kenlm/lm/interpolate/merge_probabilities.hh\n",
            "kenlm/lm/interpolate/tune_derivatives_test.cc\n",
            "kenlm/lm/interpolate/bounded_sequence_encoding.hh\n",
            "kenlm/lm/interpolate/merge_probabilities.cc\n",
            "kenlm/lm/interpolate/split_worker.cc\n",
            "kenlm/lm/partial_test.cc\n",
            "kenlm/lm/test_nounk.arpa\n",
            "kenlm/lm/model_type.hh\n",
            "kenlm/lm/builder/\n",
            "kenlm/lm/builder/adjust_counts.hh\n",
            "kenlm/lm/builder/lmplz_main.cc\n",
            "kenlm/lm/builder/header_info.hh\n",
            "kenlm/lm/builder/count_ngrams_main.cc\n",
            "kenlm/lm/builder/output.hh\n",
            "kenlm/lm/builder/combine_counts.hh\n",
            "kenlm/lm/builder/pipeline.cc\n",
            "kenlm/lm/builder/hash_gamma.hh\n",
            "kenlm/lm/builder/discount.hh\n",
            "kenlm/lm/builder/README.md\n",
            "kenlm/lm/builder/pipeline.hh\n",
            "kenlm/lm/builder/payload.hh\n",
            "kenlm/lm/builder/output.cc\n",
            "kenlm/lm/builder/dump_counts_main.cc\n",
            "kenlm/lm/builder/corpus_count.hh\n",
            "kenlm/lm/builder/initial_probabilities.cc\n",
            "kenlm/lm/builder/interpolate.hh\n",
            "kenlm/lm/builder/debug_print.hh\n",
            "kenlm/lm/builder/adjust_counts_test.cc\n",
            "kenlm/lm/builder/TODO\n",
            "kenlm/lm/builder/adjust_counts.cc\n",
            "kenlm/lm/builder/CMakeLists.txt\n",
            "kenlm/lm/builder/corpus_count_test.cc\n",
            "kenlm/lm/builder/initial_probabilities.hh\n",
            "kenlm/lm/builder/interpolate.cc\n",
            "kenlm/lm/builder/corpus_count.cc\n",
            "kenlm/lm/config.cc\n",
            "kenlm/lm/max_order.hh\n",
            "kenlm/lm/blank.hh\n",
            "kenlm/lm/trie.cc\n",
            "kenlm/lm/enumerate_vocab.hh\n",
            "kenlm/lm/quantize.cc\n",
            "kenlm/lm/model_test.cc\n",
            "kenlm/lm/sizes.cc\n",
            "kenlm/lm/virtual_interface.cc\n",
            "kenlm/lm/quantize.hh\n",
            "kenlm/lm/weights.hh\n",
            "kenlm/lm/trie_sort.hh\n",
            "kenlm/lm/fragment_main.cc\n",
            "kenlm/lm/kenlm_benchmark_main.cc\n",
            "kenlm/lm/search_hashed.hh\n",
            "kenlm/lm/facade.hh\n",
            "kenlm/lm/common/\n",
            "kenlm/lm/common/joint_order.hh\n",
            "kenlm/lm/common/model_buffer.cc\n",
            "kenlm/lm/common/compare.hh\n",
            "kenlm/lm/common/renumber.cc\n",
            "kenlm/lm/common/print.cc\n",
            "kenlm/lm/common/size_option.hh\n",
            "kenlm/lm/common/model_buffer_test.cc\n",
            "kenlm/lm/common/print.hh\n",
            "kenlm/lm/common/ngram_stream.hh\n",
            "kenlm/lm/common/test_data/\n",
            "kenlm/lm/common/test_data/toy1.arpa\n",
            "kenlm/lm/common/test_data/bigendian/\n",
            "kenlm/lm/common/test_data/bigendian/toy1.2\n",
            "kenlm/lm/common/test_data/bigendian/toy1.1\n",
            "kenlm/lm/common/test_data/bigendian/toy1.3\n",
            "kenlm/lm/common/test_data/bigendian/toy0.1\n",
            "kenlm/lm/common/test_data/bigendian/toy1.vocab\n",
            "kenlm/lm/common/test_data/bigendian/toy0.vocab\n",
            "kenlm/lm/common/test_data/bigendian/toy0.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/bigendian/toy1.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/bigendian/toy0.2\n",
            "kenlm/lm/common/test_data/bigendian/toy0.3\n",
            "kenlm/lm/common/test_data/generate.sh\n",
            "kenlm/lm/common/test_data/littleendian/\n",
            "kenlm/lm/common/test_data/littleendian/toy1.2\n",
            "kenlm/lm/common/test_data/littleendian/toy1.1\n",
            "kenlm/lm/common/test_data/littleendian/toy1.3\n",
            "kenlm/lm/common/test_data/littleendian/toy0.1\n",
            "kenlm/lm/common/test_data/littleendian/toy1.vocab\n",
            "kenlm/lm/common/test_data/littleendian/toy0.vocab\n",
            "kenlm/lm/common/test_data/littleendian/toy0.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/littleendian/toy1.kenlm_intermediate\n",
            "kenlm/lm/common/test_data/littleendian/toy0.2\n",
            "kenlm/lm/common/test_data/littleendian/toy0.3\n",
            "kenlm/lm/common/test_data/toy0.arpa\n",
            "kenlm/lm/common/ngram.hh\n",
            "kenlm/lm/common/size_option.cc\n",
            "kenlm/lm/common/model_buffer.hh\n",
            "kenlm/lm/common/CMakeLists.txt\n",
            "kenlm/lm/common/special.hh\n",
            "kenlm/lm/common/renumber.hh\n",
            "kenlm/lm/value.hh\n",
            "kenlm/lm/lm_exception.cc\n",
            "kenlm/lm/left_test.cc\n",
            "kenlm/lm/return.hh\n",
            "kenlm/lm/vocab.hh\n",
            "kenlm/lm/build_binary_main.cc\n",
            "kenlm/lm/bhiksha.cc\n",
            "kenlm/lm/value_build.cc\n",
            "kenlm/lm/model.cc\n",
            "kenlm/lm/sizes.hh\n",
            "kenlm/lm/ngram_query.hh\n",
            "kenlm/lm/lm_exception.hh\n",
            "kenlm/lm/vocab.cc\n",
            "kenlm/lm/filter/\n",
            "kenlm/lm/filter/phrase_table_vocab_main.cc\n",
            "kenlm/lm/filter/wrapper.hh\n",
            "kenlm/lm/filter/filter_main.cc\n",
            "kenlm/lm/filter/count_io.hh\n",
            "kenlm/lm/filter/phrase.cc\n",
            "kenlm/lm/filter/arpa_io.hh\n",
            "kenlm/lm/filter/vocab.hh\n",
            "kenlm/lm/filter/format.hh\n",
            "kenlm/lm/filter/thread.hh\n",
            "kenlm/lm/filter/vocab.cc\n",
            "kenlm/lm/filter/arpa_io.cc\n",
            "kenlm/lm/filter/CMakeLists.txt\n",
            "kenlm/lm/filter/phrase.hh\n",
            "kenlm/lm/wrappers/\n",
            "kenlm/lm/wrappers/README\n",
            "kenlm/lm/wrappers/nplm.hh\n",
            "kenlm/lm/wrappers/nplm.cc\n",
            "kenlm/lm/search_trie.cc\n",
            "kenlm/lm/trie_sort.cc\n",
            "kenlm/lm/word_index.hh\n",
            "kenlm/lm/state.hh\n",
            "kenlm/lm/CMakeLists.txt\n",
            "kenlm/lm/query_main.cc\n",
            "kenlm/lm/read_arpa.cc\n",
            "kenlm/lm/config.hh\n",
            "kenlm/lm/trie.hh\n",
            "kenlm/lm/search_trie.hh\n",
            "kenlm/lm/search_hashed.cc\n",
            "kenlm/lm/value_build.hh\n",
            "kenlm/CMakeLists.txt\n",
            "kenlm/LICENSE\n",
            "kenlm/Doxyfile\n",
            "kenlm/MANIFEST.in\n"
          ]
        }
      ],
      "source": [
        "!wget http://kheafield.com/code/kenlm.tar.gz\n",
        "!tar -xzvf kenlm.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL5KKFfAmRRg",
        "outputId": "65481805-b10a-41d6-b9f6-1c9fb4891a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version \"1.74.0\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework \n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done (1.2s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 52%] Built target kenlm_filter\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 61%] Built target probing_hash_table_benchmark\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 78%] Built target fragment\n",
            "[ 80%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 82%] Built target query\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 92%] Built target phrase_table_vocab\n",
            "[ 92%] Built target kenlm_benchmark\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 93%] Built target filter\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 95%] Built target kenlm_builder\n",
            "[ 96%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
            "\u001b[2K     \u001b[32m/\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184308 sha256=d66fc42b24b0154b2bba98c91ee74c0e74b1949f483593ccb3a29d1530e83f29\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h5o6u3gv/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!cd kenlm && mkdir -p build && cd build && cmake .. && make -j 4 && pip install https://github.com/kpu/kenlm/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwYgC0OpoZs7",
        "outputId": "84ff8159-56a8-42fc-cd1b-f33e3b76c5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA229AK4oeDi",
        "outputId": "b5e4a21b-ca09-4062-b3aa-2ec69e91803a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TextGAN-PyTorch\n"
          ]
        }
      ],
      "source": [
        "%cd TextGAN-PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMREk2WSognG"
      },
      "outputs": [],
      "source": [
        "!mkdir dataset\n",
        "!mkdir dataset/testdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKU1blGwlbyj",
        "outputId": "12f81414-5e75-4b17-ceea-aaa73ae29e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TextGAN-PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbJG6fkt7quR",
        "outputId": "c8b745d6-a01a-4612-f78e-870b683b1f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TextGAN-PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестовая тренировка с новыми гиперпараметрами и Трансформером"
      ],
      "metadata": {
        "id": "9AXyqsadIY5g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UREWi302psFN",
        "outputId": "65b959d1-1953-4c35-baf5-08029ba64b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total tokens:  3104\n",
            "====================================================================================================\n",
            "> training arguments:\n",
            ">>> if_test: False\n",
            ">>> run_model: catgan\n",
            ">>> k_label: 5\n",
            ">>> dataset: L1\n",
            ">>> model_type: vanilla\n",
            ">>> loss_type: ragan\n",
            ">>> mu_type: ragan\n",
            ">>> eval_type: Ra\n",
            ">>> d_type: Ra\n",
            ">>> if_real_data: 1\n",
            ">>> cuda: True\n",
            ">>> device: 0\n",
            ">>> devices: 0\n",
            ">>> shuffle: False\n",
            ">>> gen_init: truncated_normal\n",
            ">>> dis_init: uniform\n",
            ">>> n_parent: 1\n",
            ">>> eval_b_num: 8\n",
            ">>> lambda_fq: 1.0\n",
            ">>> lambda_fd: 0.0\n",
            ">>> d_out_mean: True\n",
            ">>> freeze_dis: False\n",
            ">>> freeze_clas: False\n",
            ">>> use_all_real_fake: False\n",
            ">>> use_population: False\n",
            ">>> samples_num: 10000\n",
            ">>> vocab_size: 3104\n",
            ">>> mle_epoch: 150\n",
            ">>> clas_pre_epoch: 10\n",
            ">>> adv_epoch: 80\n",
            ">>> inter_epoch: 15\n",
            ">>> batch_size: 64\n",
            ">>> max_seq_len: 31\n",
            ">>> start_letter: 1\n",
            ">>> padding_idx: 0\n",
            ">>> gen_lr: 0.0001\n",
            ">>> gen_adv_lr: 0.0001\n",
            ">>> dis_lr: 0.0001\n",
            ">>> clip_norm: 5.0\n",
            ">>> pre_log_step: 10\n",
            ">>> adv_log_step: 20\n",
            ">>> train_data: dataset/L1.txt\n",
            ">>> test_data: dataset/testdata/L1_test.txt\n",
            ">>> temp_adpt: exp\n",
            ">>> evo_temp_step: 1\n",
            ">>> temperature: 1\n",
            ">>> ora_pretrain: True\n",
            ">>> gen_pretrain: False\n",
            ">>> dis_pretrain: False\n",
            ">>> adv_g_step: 1\n",
            ">>> rollout_num: 16\n",
            ">>> gen_embed_dim: 32\n",
            ">>> gen_hidden_dim: 32\n",
            ">>> goal_size: 16\n",
            ">>> step_size: 4\n",
            ">>> mem_slots: 1\n",
            ">>> num_heads: 2\n",
            ">>> head_size: 256\n",
            ">>> d_step: 10\n",
            ">>> d_epoch: 5\n",
            ">>> adv_d_step: 5\n",
            ">>> adv_d_epoch: 3\n",
            ">>> dis_embed_dim: 64\n",
            ">>> dis_hidden_dim: 64\n",
            ">>> num_rep: 64\n",
            ">>> use_nll_oracle: True\n",
            ">>> use_nll_gen: True\n",
            ">>> use_nll_div: True\n",
            ">>> use_bleu: True\n",
            ">>> use_self_bleu: False\n",
            ">>> use_clas_acc: True\n",
            ">>> use_ppl: False\n",
            ">>> log_file: log/log_0410_2221_06.txt\n",
            ">>> save_root: save/20240410/L1/catgan_vanilla_dt-Ra_lt-ragan_mt-ra_et-Ra_sl31_temp1_lfd0.0_T0410_2221_06/\n",
            ">>> signal_file: run_signal.txt\n",
            ">>> tips: \n",
            "====================================================================================================\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "Start training Classifier...\n",
            "[PRE-CLAS] epoch 0: c_loss = 1.5938, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 1: c_loss = 1.5624, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 2: c_loss = 1.5085, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 3: c_loss = 1.4433, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 4: c_loss = 1.4337, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 5: c_loss = 1.4072, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 6: c_loss = 1.3860, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 7: c_loss = 1.3609, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 8: c_loss = 1.3293, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "[PRE-CLAS] epoch 9: c_loss = 1.2855, c_acc = 0.3906, eval_acc = 0.3822, max_eval_acc = 0.3822\n",
            "Starting Generator-0 MLE Training...\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[MLE-GEN] epoch 0 : pre_loss = 5.5861, BLEU-[2, 3, 4, 5] = [[0.055, 0.032, 0.025, 0.023], [0.069, 0.035, 0.026, 0.022], [0.033, 0.021, 0.018, 0.016], [0.063, 0.033, 0.025, 0.022], [0.041, 0.026, 0.022, 0.021]], NLL_gen = [4.4948, 4.5177, 4.2274, 4.784, 3.9932], NLL_div = [4.463, 4.7357, 4.1676, 4.8652, 4.033], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 10 : pre_loss = 3.5758, BLEU-[2, 3, 4, 5] = [[0.137, 0.055, 0.037, 0.03], [0.187, 0.068, 0.041, 0.031], [0.079, 0.039, 0.029, 0.025], [0.189, 0.062, 0.036, 0.027], [0.096, 0.046, 0.034, 0.03]], NLL_gen = [3.5306, 3.604, 3.3093, 3.721, 3.0497], NLL_div = [3.4282, 3.6389, 3.1567, 3.8148, 2.8385], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 20 : pre_loss = 3.3526, BLEU-[2, 3, 4, 5] = [[0.158, 0.054, 0.033, 0.025], [0.214, 0.067, 0.037, 0.027], [0.097, 0.042, 0.029, 0.024], [0.231, 0.069, 0.037, 0.026], [0.124, 0.05, 0.034, 0.028]], NLL_gen = [3.2949, 3.4206, 2.9726, 3.5312, 2.7484], NLL_div = [3.4292, 3.6802, 3.0824, 3.6411, 2.8318], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 30 : pre_loss = 3.2313, BLEU-[2, 3, 4, 5] = [[0.195, 0.063, 0.037, 0.027], [0.216, 0.068, 0.038, 0.028], [0.092, 0.038, 0.026, 0.021], [0.232, 0.068, 0.036, 0.025], [0.136, 0.053, 0.034, 0.028]], NLL_gen = [3.182, 3.3071, 2.7967, 3.4245, 2.5871], NLL_div = [3.1253, 3.3821, 2.966, 3.6288, 2.6959], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 40 : pre_loss = 3.1384, BLEU-[2, 3, 4, 5] = [[0.184, 0.06, 0.035, 0.026], [0.233, 0.072, 0.039, 0.028], [0.099, 0.04, 0.026, 0.021], [0.249, 0.073, 0.038, 0.026], [0.127, 0.05, 0.034, 0.028]], NLL_gen = [3.0778, 3.2254, 2.676, 3.3594, 2.4682], NLL_div = [3.1195, 3.4447, 3.0569, 3.6611, 2.6288], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 50 : pre_loss = 3.0522, BLEU-[2, 3, 4, 5] = [[0.219, 0.068, 0.038, 0.027], [0.252, 0.075, 0.041, 0.029], [0.104, 0.042, 0.029, 0.023], [0.272, 0.076, 0.039, 0.027], [0.148, 0.055, 0.035, 0.028]], NLL_gen = [2.992, 3.1382, 2.5895, 3.2703, 2.377], NLL_div = [3.1639, 3.2902, 2.7813, 3.5368, 2.612], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 60 : pre_loss = 2.9620, BLEU-[2, 3, 4, 5] = [[0.206, 0.065, 0.036, 0.026], [0.245, 0.073, 0.039, 0.027], [0.099, 0.039, 0.026, 0.021], [0.251, 0.077, 0.04, 0.027], [0.141, 0.054, 0.034, 0.027]], NLL_gen = [2.8991, 3.0497, 2.4908, 3.1698, 2.2923], NLL_div = [3.1973, 3.325, 2.9365, 3.5084, 2.769], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 70 : pre_loss = 2.8547, BLEU-[2, 3, 4, 5] = [[0.222, 0.067, 0.037, 0.027], [0.245, 0.082, 0.044, 0.031], [0.112, 0.043, 0.027, 0.022], [0.293, 0.083, 0.041, 0.028], [0.165, 0.06, 0.038, 0.029]], NLL_gen = [2.8039, 2.9467, 2.3876, 3.0846, 2.2026], NLL_div = [3.0314, 3.1333, 2.8456, 3.3312, 2.454], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 80 : pre_loss = 2.7369, BLEU-[2, 3, 4, 5] = [[0.252, 0.079, 0.042, 0.029], [0.259, 0.081, 0.042, 0.03], [0.117, 0.044, 0.028, 0.022], [0.304, 0.094, 0.046, 0.03], [0.167, 0.06, 0.037, 0.028]], NLL_gen = [2.6974, 2.8561, 2.2804, 2.9894, 2.1062], NLL_div = [3.0122, 3.1634, 2.6988, 3.2646, 2.5181], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 90 : pre_loss = 2.6066, BLEU-[2, 3, 4, 5] = [[0.237, 0.074, 0.041, 0.029], [0.271, 0.091, 0.047, 0.032], [0.12, 0.045, 0.029, 0.023], [0.293, 0.095, 0.047, 0.031], [0.162, 0.059, 0.036, 0.028]], NLL_gen = [2.5788, 2.7169, 2.1676, 2.8357, 1.9917], NLL_div = [2.8861, 3.0392, 2.6193, 3.128, 2.4206], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 100 : pre_loss = 2.4856, BLEU-[2, 3, 4, 5] = [[0.254, 0.086, 0.047, 0.033], [0.286, 0.1, 0.053, 0.036], [0.142, 0.054, 0.034, 0.027], [0.318, 0.104, 0.05, 0.033], [0.21, 0.076, 0.046, 0.035]], NLL_gen = [2.4715, 2.6382, 2.0887, 2.7499, 1.9388], NLL_div = [2.5923, 2.6773, 2.2983, 2.827, 2.1106], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 110 : pre_loss = 2.3497, BLEU-[2, 3, 4, 5] = [[0.242, 0.084, 0.044, 0.031], [0.285, 0.111, 0.059, 0.039], [0.119, 0.046, 0.029, 0.023], [0.331, 0.113, 0.054, 0.035], [0.187, 0.069, 0.042, 0.032]], NLL_gen = [2.2997, 2.4478, 1.9355, 2.589, 1.7776], NLL_div = [2.6511, 2.7337, 2.3055, 2.9274, 2.1407], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 120 : pre_loss = 2.1979, BLEU-[2, 3, 4, 5] = [[0.276, 0.093, 0.049, 0.034], [0.34, 0.13, 0.066, 0.041], [0.141, 0.054, 0.033, 0.025], [0.381, 0.132, 0.062, 0.038], [0.203, 0.075, 0.045, 0.034]], NLL_gen = [2.1345, 2.2973, 1.7974, 2.4324, 1.6528], NLL_div = [2.4937, 2.627, 2.2141, 2.7299, 2.0961], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 130 : pre_loss = 2.0636, BLEU-[2, 3, 4, 5] = [[0.277, 0.094, 0.048, 0.033], [0.35, 0.138, 0.068, 0.042], [0.136, 0.05, 0.032, 0.024], [0.342, 0.113, 0.054, 0.034], [0.207, 0.076, 0.043, 0.032]], NLL_gen = [2.0014, 2.1741, 1.6937, 2.2865, 1.5811], NLL_div = [2.5695, 2.6827, 2.2797, 2.7749, 2.0993], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 140 : pre_loss = 1.9512, BLEU-[2, 3, 4, 5] = [[0.304, 0.093, 0.048, 0.032], [0.343, 0.139, 0.076, 0.047], [0.147, 0.052, 0.032, 0.025], [0.366, 0.127, 0.059, 0.038], [0.215, 0.077, 0.045, 0.033]], NLL_gen = [1.9149, 2.0581, 1.5969, 2.1973, 1.4972], NLL_div = [2.4072, 2.5217, 2.1196, 2.5741, 2.002], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "[MLE-GEN] epoch 149 : pre_loss = 1.8446, BLEU-[2, 3, 4, 5] = [[0.255, 0.086, 0.044, 0.03], [0.316, 0.118, 0.061, 0.038], [0.135, 0.049, 0.03, 0.024], [0.347, 0.118, 0.056, 0.035], [0.197, 0.069, 0.041, 0.031]], NLL_gen = [1.8682, 1.9646, 1.5205, 2.104, 1.4087], NLL_div = [2.5426, 2.595, 2.2076, 2.7519, 2.0203], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "Save pre-trained generator: pretrain/L1/gen_MLE_pretrain_catgan_vanilla_sl31_sn10000.pt0\n",
            "mu: ragan, d_loss = 6.9286, temp = 1.0000:   0% 0/80 [00:18<?, ?it/s][ADV] epoch 0: temp = 1.0000, d_loss: 6.9286, BLEU-[2, 3, 4, 5] = [[0.247, 0.08, 0.042, 0.028], [0.304, 0.109, 0.055, 0.035], [0.123, 0.046, 0.029, 0.023], [0.344, 0.113, 0.053, 0.034], [0.175, 0.062, 0.036, 0.027]], NLL_gen = [1.8673, 1.9615, 1.5271, 2.0955, 1.4242], NLL_div = [2.5558, 2.5875, 2.2124, 2.7318, 2.0556], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "mu: ragan, d_loss = 5.0395, temp = 1.0000:  25% 20/80 [07:32<16:39, 16.67s/it][ADV] epoch 20: temp = 1.0000, d_loss: 5.0395, BLEU-[2, 3, 4, 5] = [[0.385, 0.143, 0.067, 0.038], [0.465, 0.281, 0.161, 0.094], [0.197, 0.057, 0.029, 0.019], [0.354, 0.137, 0.064, 0.037], [0.308, 0.088, 0.044, 0.029]], NLL_gen = [7.5248, 6.6693, 7.8507, 7.0505, 5.985], NLL_div = [1.202, 1.2086, 1.2758, 1.4131, 1.1252], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "mu: ragan, d_loss = 0.1838, temp = 1.0000:  50% 40/80 [14:42<11:09, 16.73s/it][ADV] epoch 40: temp = 1.0000, d_loss: 0.1838, BLEU-[2, 3, 4, 5] = [[0.109, 0.036, 0.02, 0.014], [0.144, 0.043, 0.023, 0.016], [0.031, 0.015, 0.011, 0.009], [0.14, 0.045, 0.024, 0.016], [0.185, 0.059, 0.033, 0.024]], NLL_gen = [9.9204, 9.4777, 9.0624, 10.2761, 9.2606], NLL_div = [0.9312, 1.0798, 0.7146, 0.9649, 0.5863], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "mu: ragan, d_loss = 0.0417, temp = 1.0000:  75% 60/80 [21:51<05:36, 16.81s/it][ADV] epoch 60: temp = 1.0000, d_loss: 0.0417, BLEU-[2, 3, 4, 5] = [[0.123, 0.038, 0.021, 0.015], [0.148, 0.043, 0.023, 0.016], [0.042, 0.018, 0.012, 0.009], [0.114, 0.037, 0.02, 0.014], [0.078, 0.027, 0.016, 0.012]], NLL_gen = [18.106, 17.1794, 17.0397, 16.7648, 15.5934], NLL_div = [0.6315, 0.6598, 0.6858, 0.6441, 0.7408], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "mu: ragan, d_loss = 0.0142, temp = 1.0000:  99% 79/80 [28:43<00:16, 16.73s/it][ADV] epoch 79: temp = 1.0000, d_loss: 0.0142, BLEU-[2, 3, 4, 5] = [[0.085, 0.029, 0.017, 0.012], [0.088, 0.031, 0.018, 0.013], [0.03, 0.014, 0.01, 0.008], [0.077, 0.027, 0.016, 0.012], [0.062, 0.024, 0.014, 0.011]], NLL_gen = [16.6272, 15.9869, 17.1702, 15.5732, 16.2333], NLL_div = [0.6091, 0.6088, 0.6009, 0.6324, 0.5523], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "mu: ragan, d_loss = 0.0142, temp = 1.0000: 100% 80/80 [30:17<00:00, 22.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!python main.py --run_model catgan --dataset L1 --if_real_data 1 --k_label 5 --loss_type ragan --gen_lr 0.0001 --gen_adv_lr 0.00001 --mle_epoch 150 --adv_epoch 80 --d_step 10 --d_epoch 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/content.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "wjntTFf7NWhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чистовая тренировка с окончательными файлами"
      ],
      "metadata": {
        "id": "BlJ8vAjoInSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --run_model catgan --dataset L1 --if_real_data 1 --k_label 5 --loss_type ragan --gen_pretrain 1 --gen_adv_lr 0.0000001 --adv_epoch 500 --d_step 10 --d_epoch 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5r5R3bC5NjA",
        "outputId": "01b374c8-6b84-40c3-8001-a9d78163ab7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "> training arguments:\n",
            ">>> if_test: False\n",
            ">>> run_model: catgan\n",
            ">>> k_label: 5\n",
            ">>> dataset: L1\n",
            ">>> model_type: vanilla\n",
            ">>> loss_type: ragan\n",
            ">>> mu_type: ragan\n",
            ">>> eval_type: Ra\n",
            ">>> d_type: Ra\n",
            ">>> if_real_data: 1\n",
            ">>> cuda: True\n",
            ">>> device: 0\n",
            ">>> devices: 0\n",
            ">>> shuffle: False\n",
            ">>> gen_init: truncated_normal\n",
            ">>> dis_init: uniform\n",
            ">>> n_parent: 1\n",
            ">>> eval_b_num: 8\n",
            ">>> lambda_fq: 1.0\n",
            ">>> lambda_fd: 0.0\n",
            ">>> d_out_mean: True\n",
            ">>> freeze_dis: False\n",
            ">>> freeze_clas: False\n",
            ">>> use_all_real_fake: False\n",
            ">>> use_population: False\n",
            ">>> samples_num: 10000\n",
            ">>> vocab_size: 3104\n",
            ">>> mle_epoch: 150\n",
            ">>> clas_pre_epoch: 10\n",
            ">>> adv_epoch: 500\n",
            ">>> inter_epoch: 15\n",
            ">>> batch_size: 64\n",
            ">>> max_seq_len: 31\n",
            ">>> start_letter: 1\n",
            ">>> padding_idx: 0\n",
            ">>> gen_lr: 0.01\n",
            ">>> gen_adv_lr: 1e-07\n",
            ">>> dis_lr: 0.0001\n",
            ">>> clip_norm: 5.0\n",
            ">>> pre_log_step: 10\n",
            ">>> adv_log_step: 20\n",
            ">>> train_data: dataset/L1.txt\n",
            ">>> test_data: dataset/testdata/L1_test.txt\n",
            ">>> temp_adpt: exp\n",
            ">>> evo_temp_step: 1\n",
            ">>> temperature: 1\n",
            ">>> ora_pretrain: True\n",
            ">>> gen_pretrain: 1\n",
            ">>> dis_pretrain: False\n",
            ">>> adv_g_step: 1\n",
            ">>> rollout_num: 16\n",
            ">>> gen_embed_dim: 32\n",
            ">>> gen_hidden_dim: 32\n",
            ">>> goal_size: 16\n",
            ">>> step_size: 4\n",
            ">>> mem_slots: 1\n",
            ">>> num_heads: 2\n",
            ">>> head_size: 256\n",
            ">>> d_step: 10\n",
            ">>> d_epoch: 5\n",
            ">>> adv_d_step: 5\n",
            ">>> adv_d_epoch: 3\n",
            ">>> dis_embed_dim: 64\n",
            ">>> dis_hidden_dim: 64\n",
            ">>> num_rep: 64\n",
            ">>> use_nll_oracle: True\n",
            ">>> use_nll_gen: True\n",
            ">>> use_nll_div: True\n",
            ">>> use_bleu: True\n",
            ">>> use_self_bleu: False\n",
            ">>> use_clas_acc: True\n",
            ">>> use_ppl: False\n",
            ">>> log_file: log/log_0506_2301_38.txt\n",
            ">>> save_root: save/20240506/L1/catgan_vanilla_dt-Ra_lt-ragan_mt-ra_et-Ra_sl31_temp1_lfd0.0_T0506_2301_38/\n",
            ">>> signal_file: run_signal.txt\n",
            ">>> tips: \n",
            "====================================================================================================\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "Load MLE pretrained generator gen: pretrain/L1/gen_MLE_pretrain_catgan_vanilla_sl31_sn10000.pt0\n",
            "Start training Classifier...\n",
            "[PRE-CLAS] epoch 0: c_loss = 1.5916, c_acc = 0.3672, eval_acc = 0.3834, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 1: c_loss = 1.5619, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 2: c_loss = 1.5095, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 3: c_loss = 1.4449, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 4: c_loss = 1.4301, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 5: c_loss = 1.4087, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 6: c_loss = 1.3899, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 7: c_loss = 1.3546, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 8: c_loss = 1.3218, c_acc = 0.3776, eval_acc = 0.3828, max_eval_acc = 0.3834\n",
            "[PRE-CLAS] epoch 9: c_loss = 1.2739, c_acc = 0.3776, eval_acc = 0.3834, max_eval_acc = 0.3834\n",
            "mu: ragan, d_loss = 6.9295, temp = 1.0000:   0% 0/500 [00:18<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[ADV] epoch 0: temp = 1.0000, d_loss: 6.9295, BLEU-[2, 3, 4, 5] = [[0.364, 0.14, 0.073, 0.048], [0.437, 0.206, 0.118, 0.07], [0.171, 0.066, 0.038, 0.028], [0.478, 0.204, 0.101, 0.058], [0.251, 0.098, 0.057, 0.041]], NLL_gen = [0.8336, 0.8379, 0.7431, 0.879, 0.714], NLL_div = [1.4957, 1.5425, 1.394, 1.6508, 1.2572], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9982, 0.0, 0.0016, 0.0]\n",
            "mu: ragan, d_loss = 5.3260, temp = 1.0000:   4% 20/500 [07:48<2:16:29, 17.06s/it][ADV] epoch 20: temp = 1.0000, d_loss: 5.3260, BLEU-[2, 3, 4, 5] = [[0.347, 0.142, 0.073, 0.046], [0.43, 0.203, 0.107, 0.064], [0.184, 0.067, 0.038, 0.028], [0.464, 0.202, 0.099, 0.057], [0.263, 0.103, 0.059, 0.042]], NLL_gen = [0.8338, 0.8381, 0.7433, 0.8794, 0.7142], NLL_div = [1.4954, 1.5408, 1.3915, 1.6446, 1.2689], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9986, 0.0, 0.0008, 0.0]\n",
            "mu: ragan, d_loss = 0.2512, temp = 1.0000:   8% 40/500 [15:20<2:15:48, 17.71s/it][ADV] epoch 40: temp = 1.0000, d_loss: 0.2512, BLEU-[2, 3, 4, 5] = [[0.358, 0.141, 0.076, 0.05], [0.43, 0.204, 0.107, 0.064], [0.179, 0.069, 0.039, 0.029], [0.486, 0.201, 0.096, 0.056], [0.276, 0.11, 0.062, 0.044]], NLL_gen = [0.834, 0.8383, 0.7434, 0.8799, 0.7144], NLL_div = [1.4971, 1.536, 1.3862, 1.6436, 1.2585], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9986, 0.0, 0.0011, 0.0]\n",
            "mu: ragan, d_loss = 0.0480, temp = 1.0000:  12% 60/500 [22:41<2:04:48, 17.02s/it][ADV] epoch 60: temp = 1.0000, d_loss: 0.0480, BLEU-[2, 3, 4, 5] = [[0.354, 0.135, 0.07, 0.045], [0.463, 0.228, 0.125, 0.076], [0.178, 0.068, 0.039, 0.029], [0.468, 0.201, 0.099, 0.059], [0.253, 0.1, 0.056, 0.039]], NLL_gen = [0.8341, 0.8383, 0.7433, 0.8801, 0.7145], NLL_div = [1.4943, 1.5415, 1.3929, 1.6413, 1.2613], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9985, 0.0, 0.0011, 0.0]\n",
            "mu: ragan, d_loss = 0.0169, temp = 1.0000:  16% 80/500 [30:06<2:03:18, 17.62s/it][ADV] epoch 80: temp = 1.0000, d_loss: 0.0169, BLEU-[2, 3, 4, 5] = [[0.361, 0.142, 0.074, 0.047], [0.453, 0.21, 0.106, 0.062], [0.167, 0.06, 0.036, 0.028], [0.466, 0.196, 0.094, 0.056], [0.267, 0.102, 0.059, 0.042]], NLL_gen = [0.8341, 0.8383, 0.7431, 0.88, 0.7145], NLL_div = [1.4931, 1.5389, 1.3907, 1.6405, 1.2585], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.999, 0.0, 0.0015, 0.0]\n",
            "mu: ragan, d_loss = 0.0099, temp = 1.0000:  20% 100/500 [37:29<1:52:59, 16.95s/it][ADV] epoch 100: temp = 1.0000, d_loss: 0.0099, BLEU-[2, 3, 4, 5] = [[0.365, 0.14, 0.07, 0.045], [0.415, 0.191, 0.105, 0.065], [0.185, 0.068, 0.039, 0.029], [0.491, 0.224, 0.111, 0.065], [0.261, 0.093, 0.053, 0.038]], NLL_gen = [0.834, 0.8382, 0.7429, 0.8799, 0.7145], NLL_div = [1.4874, 1.5388, 1.3917, 1.6391, 1.255], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9991, 0.0, 0.0017, 0.0]\n",
            "mu: ragan, d_loss = 0.0062, temp = 1.0000:  24% 120/500 [44:47<1:47:20, 16.95s/it][ADV] epoch 120: temp = 1.0000, d_loss: 0.0062, BLEU-[2, 3, 4, 5] = [[0.366, 0.14, 0.071, 0.045], [0.418, 0.194, 0.108, 0.069], [0.177, 0.067, 0.04, 0.029], [0.473, 0.204, 0.094, 0.055], [0.261, 0.103, 0.061, 0.042]], NLL_gen = [0.8339, 0.8381, 0.7428, 0.8798, 0.7145], NLL_div = [1.4973, 1.53, 1.3828, 1.6425, 1.2623], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9995, 0.0, 0.0012, 0.0]\n",
            "mu: ragan, d_loss = 0.0044, temp = 1.0000:  28% 140/500 [52:14<1:45:31, 17.59s/it][ADV] epoch 140: temp = 1.0000, d_loss: 0.0044, BLEU-[2, 3, 4, 5] = [[0.362, 0.141, 0.074, 0.047], [0.432, 0.208, 0.117, 0.072], [0.171, 0.065, 0.039, 0.029], [0.476, 0.214, 0.108, 0.067], [0.255, 0.096, 0.055, 0.04]], NLL_gen = [0.8338, 0.8381, 0.7426, 0.8798, 0.7145], NLL_div = [1.478, 1.5339, 1.3805, 1.6422, 1.2446], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9987, 0.0, 0.0009, 0.0]\n",
            "mu: ragan, d_loss = 0.0029, temp = 1.0000:  32% 160/500 [59:34<1:35:12, 16.80s/it][ADV] epoch 160: temp = 1.0000, d_loss: 0.0029, BLEU-[2, 3, 4, 5] = [[0.352, 0.141, 0.074, 0.047], [0.428, 0.206, 0.112, 0.068], [0.18, 0.069, 0.039, 0.029], [0.464, 0.201, 0.093, 0.055], [0.254, 0.098, 0.056, 0.04]], NLL_gen = [0.8338, 0.8381, 0.7425, 0.8797, 0.7145], NLL_div = [1.4878, 1.5299, 1.3926, 1.6413, 1.2548], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.999, 0.0, 0.0012, 0.0]\n",
            "mu: ragan, d_loss = 0.0021, temp = 1.0000:  36% 180/500 [1:06:52<1:29:07, 16.71s/it][ADV] epoch 180: temp = 1.0000, d_loss: 0.0021, BLEU-[2, 3, 4, 5] = [[0.356, 0.137, 0.068, 0.045], [0.454, 0.224, 0.13, 0.081], [0.198, 0.072, 0.042, 0.031], [0.49, 0.219, 0.111, 0.064], [0.26, 0.095, 0.055, 0.04]], NLL_gen = [0.8338, 0.8381, 0.7424, 0.8797, 0.7145], NLL_div = [1.4855, 1.5255, 1.371, 1.6368, 1.2535], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9982, 0.0, 0.0015, 0.0]\n",
            "mu: ragan, d_loss = 0.0016, temp = 1.0000:  40% 200/500 [1:14:06<1:23:02, 16.61s/it][ADV] epoch 200: temp = 1.0000, d_loss: 0.0016, BLEU-[2, 3, 4, 5] = [[0.373, 0.142, 0.074, 0.047], [0.426, 0.19, 0.102, 0.062], [0.178, 0.065, 0.039, 0.029], [0.468, 0.208, 0.101, 0.057], [0.265, 0.1, 0.056, 0.039]], NLL_gen = [0.8338, 0.8381, 0.7424, 0.8796, 0.7146], NLL_div = [1.482, 1.5329, 1.3689, 1.6352, 1.258], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9986, 0.0, 0.0007, 0.0]\n",
            "mu: ragan, d_loss = 0.0016, temp = 1.0000:  44% 220/500 [1:21:23<1:19:10, 16.97s/it][ADV] epoch 220: temp = 1.0000, d_loss: 0.0016, BLEU-[2, 3, 4, 5] = [[0.368, 0.143, 0.073, 0.047], [0.438, 0.203, 0.109, 0.066], [0.181, 0.069, 0.04, 0.029], [0.484, 0.217, 0.106, 0.062], [0.279, 0.107, 0.06, 0.042]], NLL_gen = [0.8339, 0.8382, 0.7424, 0.8797, 0.7147], NLL_div = [1.484, 1.5362, 1.3673, 1.6396, 1.2528], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9992, 0.0, 0.0006, 0.0]\n",
            "mu: ragan, d_loss = 0.0011, temp = 1.0000:  48% 240/500 [1:28:34<1:12:08, 16.65s/it][ADV] epoch 240: temp = 1.0000, d_loss: 0.0011, BLEU-[2, 3, 4, 5] = [[0.367, 0.139, 0.071, 0.046], [0.457, 0.208, 0.11, 0.067], [0.197, 0.068, 0.039, 0.029], [0.463, 0.193, 0.094, 0.057], [0.268, 0.1, 0.057, 0.04]], NLL_gen = [0.834, 0.8383, 0.7425, 0.8797, 0.7148], NLL_div = [1.4838, 1.5277, 1.3826, 1.6391, 1.237], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.999, 0.0, 0.0017, 0.0]\n",
            "mu: ragan, d_loss = 0.0007, temp = 1.0000:  52% 260/500 [1:35:51<1:07:10, 16.79s/it][ADV] epoch 260: temp = 1.0000, d_loss: 0.0007, BLEU-[2, 3, 4, 5] = [[0.369, 0.146, 0.075, 0.048], [0.429, 0.195, 0.105, 0.064], [0.185, 0.067, 0.04, 0.03], [0.487, 0.218, 0.105, 0.06], [0.28, 0.109, 0.061, 0.043]], NLL_gen = [0.8342, 0.8384, 0.7426, 0.8798, 0.7149], NLL_div = [1.4874, 1.5308, 1.3727, 1.6355, 1.2495], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9993, 0.0, 0.0011, 0.0]\n",
            "mu: ragan, d_loss = 0.0007, temp = 1.0000:  56% 280/500 [1:43:05<1:00:52, 16.60s/it][ADV] epoch 280: temp = 1.0000, d_loss: 0.0007, BLEU-[2, 3, 4, 5] = [[0.362, 0.142, 0.075, 0.049], [0.427, 0.197, 0.107, 0.065], [0.183, 0.068, 0.039, 0.029], [0.484, 0.212, 0.104, 0.061], [0.266, 0.108, 0.063, 0.045]], NLL_gen = [0.8343, 0.8386, 0.7427, 0.88, 0.7151], NLL_div = [1.4818, 1.5258, 1.3687, 1.6371, 1.2405], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9982, 0.0, 0.0013, 0.0]\n",
            "mu: ragan, d_loss = 0.0004, temp = 1.0000:  60% 300/500 [1:50:19<56:11, 16.86s/it][ADV] epoch 300: temp = 1.0000, d_loss: 0.0004, BLEU-[2, 3, 4, 5] = [[0.362, 0.146, 0.076, 0.05], [0.432, 0.207, 0.117, 0.073], [0.177, 0.067, 0.039, 0.03], [0.494, 0.23, 0.118, 0.069], [0.269, 0.105, 0.061, 0.042]], NLL_gen = [0.8345, 0.8388, 0.7429, 0.8802, 0.7153], NLL_div = [1.4841, 1.5255, 1.3759, 1.6394, 1.2507], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9986, 0.0, 0.0012, 0.0]\n",
            "mu: ragan, d_loss = 0.0004, temp = 1.0000:  64% 320/500 [1:57:32<50:22, 16.79s/it][ADV] epoch 320: temp = 1.0000, d_loss: 0.0004, BLEU-[2, 3, 4, 5] = [[0.386, 0.154, 0.081, 0.052], [0.429, 0.201, 0.11, 0.065], [0.204, 0.076, 0.043, 0.031], [0.47, 0.206, 0.101, 0.059], [0.27, 0.102, 0.059, 0.042]], NLL_gen = [0.8348, 0.839, 0.7431, 0.8804, 0.7155], NLL_div = [1.4754, 1.5156, 1.374, 1.6335, 1.235], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.999, 0.0, 0.0012, 0.0]\n",
            "mu: ragan, d_loss = 0.0003, temp = 1.0000:  68% 340/500 [2:04:51<45:11, 16.95s/it][ADV] epoch 340: temp = 1.0000, d_loss: 0.0003, BLEU-[2, 3, 4, 5] = [[0.382, 0.151, 0.075, 0.048], [0.445, 0.218, 0.121, 0.074], [0.177, 0.066, 0.039, 0.03], [0.479, 0.216, 0.108, 0.062], [0.271, 0.108, 0.062, 0.043]], NLL_gen = [0.8351, 0.8392, 0.7434, 0.8806, 0.7158], NLL_div = [1.4878, 1.5288, 1.3654, 1.6384, 1.2448], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9992, 0.0, 0.0014, 0.0]\n",
            "mu: ragan, d_loss = 0.0003, temp = 1.0000:  72% 360/500 [2:12:05<39:17, 16.84s/it][ADV] epoch 360: temp = 1.0000, d_loss: 0.0003, BLEU-[2, 3, 4, 5] = [[0.387, 0.16, 0.09, 0.056], [0.435, 0.198, 0.103, 0.063], [0.184, 0.068, 0.041, 0.031], [0.482, 0.213, 0.106, 0.06], [0.272, 0.107, 0.062, 0.044]], NLL_gen = [0.8354, 0.8395, 0.7437, 0.8809, 0.7161], NLL_div = [1.4704, 1.525, 1.3633, 1.6296, 1.2346], Self-BLEU-[2, 3, 4] = [0, 0, 0, 0, 0], [PPL-F, PPL-R] = [0, 0, 0, 0, 0], clas_acc = [0.0, 0.9983, 0.0, 0.0013, 0.0]\n",
            "mu: ragan, d_loss = 0.0003, temp = 1.0000:  72% 361/500 [2:13:46<51:30, 22.24s/it]  \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TextGAN-PyTorch/main.py\", line 169, in <module>\n",
            "    inst._run()\n",
            "  File \"/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 111, in _run\n",
            "    score, fit_score, select_mu = self.evolve_generator(cfg.ADV_g_step)\n",
            "  File \"/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 173, in evolve_generator\n",
            "    real_samples = [real_samples[i].cuda() for i in range(cfg.k_label)]\n",
            "  File \"/content/TextGAN-PyTorch/instructor/real_data/catgan_instructor.py\", line 173, in <listcomp>\n",
            "    real_samples = [real_samples[i].cuda() for i in range(cfg.k_label)]\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zGxJspSMkpW"
      },
      "outputs": [],
      "source": [
        "!zip -r adv_gan.zip /content/TextGAN-PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_E6u-nD2qDkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_NT5KlGod7mI",
        "4DEKD8EkmeAo"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}